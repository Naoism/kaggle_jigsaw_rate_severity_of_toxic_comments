{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":8137,"status":"ok","timestamp":1644192661417,"user":{"displayName":"棚橋直哉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07887718494945196844"},"user_tz":-540},"id":"6jAlHEbOrwBj"},"outputs":[],"source":["!pip -q install transformers\n","!pip -q install sentencepiece"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":2687,"status":"ok","timestamp":1644129773340,"user":{"displayName":"棚橋直哉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07887718494945196844"},"user_tz":-540},"id":"_Orve55gqWsW"},"outputs":[],"source":["import os\n","import sys\n","import numpy as np\n","import pandas as pd\n","import math\n","import time\n","import random\n","import shutil\n","import copy\n","import collections\n","from pathlib import Path\n","from contextlib import contextmanager\n","from collections import defaultdict, Counter\n","from sklearn import preprocessing\n","from sklearn.metrics import roc_auc_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","from tqdm.auto import tqdm\n","from functools import partial\n","import torch\n","import torch.nn as nn\n","from torch.nn import MarginRankingLoss\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import Adam, SGD\n","import torchvision.models as models\n","from torch.nn.parameter import Parameter\n","from torch.utils.data import DataLoader, Dataset\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","import transformers\n","from transformers import (AutoModel, AutoTokenizer)\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","from torch.cuda.amp import autocast, GradScaler\n","import re\n","from bs4 import BeautifulSoup\n","tqdm.pandas()\n","\n","device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    ######################\n","    # Globals #\n","    ######################\n","    debug = False\n","    exp_name = \"exp4001\"\n","    fold_seed = 0\n","    seed = 0\n","    start_epoch = 0\n","    epochs = 5\n","    train = True\n","    folds = [0,1,2,3,4]\n","    n_fold = 5\n","    print_freq = 100\n","    use_amp = True\n","    target_col = \"pseudo_label\"\n","    ######################\n","    # Dataset #\n","    ######################\n","    head = 64\n","    tail = 64\n","    max_length = head+tail\n","    under_sampling = False\n","    under_sampling_ratio = 0.1\n","    ######################\n","    # Augmentation #\n","    ######################\n","\n","    ######################\n","    # Loaders #\n","    ######################\n","    batch_size = 64\n","    num_workers = 8\n","    ######################\n","    # Model #\n","    ######################\n","    # https://huggingface.co/deepset/xlm-roberta-base-squad2\n","    base_model_name = \"unitary/multilingual-toxic-xlm-roberta\"\n","    pretrained = True\n","    num_classes = 1  # Binary \n","    hidden_node = 768  # large: 1024, base: 768\n","    ######################\n","    # Criterion #\n","    ######################\n","    loss_name = \"MSELoss\"\n","    loss_params: dict = {}\n","    ######################\n","    # Optimizer #\n","    ######################\n","    optimizer_name = \"AdamW\"\n","    optimizer_params = {\n","        \"lr\": 1e-5,\n","    }\n","    ######################\n","    # Scheduler #\n","    ######################\n","    scheduler = \"cosine\"\n","    num_cycles=0.5\n","    num_warmup_steps_ratio = 0.1\n","    \n","\n","# ====================================================\n","# Directory settings\n","# ====================================================\n","INPUT_PATH = \"../input/\"\n","OUTPUT_DIR = f'../output/{CFG.exp_name}/' \n","if not os.path.exists(OUTPUT_DIR):\n","    os.makedirs(OUTPUT_DIR)\n","\n","\n","# ====================================================\n","# Utils\n","# ====================================================\n","\n","def seed_torch(seed=42):\n","    random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","\n","def init_logger(log_file=OUTPUT_DIR+\"train.log\"):\n","    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=log_file)\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","    \n","LOGGER = init_logger()\n","\n","def get_score(more_toxic_preds, less_toxic_preds):\n","    score = np.mean(more_toxic_preds > less_toxic_preds)\n","    return score\n","\n","\n","\n","def get_result(df):\n","    more_toxic_preds = df[\"more_toxic_preds\"].values\n","    less_toxic_preds = df[\"less_toxic_preds\"].values\n","    score = get_score(more_toxic_preds, less_toxic_preds)\n","    LOGGER.info(f\"Score: {score:<.4f}\")\n","    return score\n","\n","def read_processed_data():\n","    validation_data = pd.read_csv(INPUT_PATH + \"validation_data.csv\")\n","    test = pd.read_csv(INPUT_PATH + \"comments_to_score.csv\")\n","    sub = pd.read_csv(INPUT_PATH + \"sample_submission.csv\")\n","    train_src = pd.read_csv(\"../input/jigsaw_1st/PseudoLabelDataset.csv\")\n","    val_comment_unq = pd.concat([validation_data['less_toxic'], validation_data['more_toxic']]).unique()\n","    train2017 = train_src[~train_src['comment_text'].isin(val_comment_unq)]\n","    print(train2017.head())\n","    return train2017, validation_data, test, sub\n","\n","def text_cleaning(text):\n","    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n","    text = template.sub(r'', text)\n","    template = re.compile(r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\") #Removes e-mail address\n","    text = template.sub(r'.', text)\n","    # text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n","    ipPattern = re.compile('\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}') # Removes IP address\n","    text = ipPattern.sub(r'', text)\n","    text = text.replace('\\n','')\n","    text = text.strip() # remove spaces at the beginning and at the end of string\n","    return text\n","\n","# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n","\n","\n","def prepare_input(text, tokenizer):\n","    if CFG.tail == 0:\n","        inputs = tokenizer.encode_plus(\n","            text, \n","            return_tensors=None, \n","            add_special_tokens=True, \n","            max_length=CFG.max_length,\n","            pad_to_max_length=True,\n","            truncation=True\n","            )\n","        for k, v in inputs.items():\n","            inputs[k] = torch.tensor(v, dtype=torch.long)\n","    else:\n","        inputs = tokenizer.encode_plus(\n","            text,\n","            return_tensors=None, \n","            add_special_tokens=True, \n","            truncation=True\n","            )\n","        for k, v in inputs.items():\n","            v_length = len(v)\n","            if v_length > CFG.max_length:\n","                v = np.hstack([v[:CFG.head], v[-CFG.tail:]])\n","            if k == 'input_ids':\n","                new_v = np.ones(CFG.max_length) * tokenizer.pad_token_id\n","            else:\n","                new_v = np.zeros(CFG.max_length)\n","            new_v[:v_length] = v \n","            inputs[k] = torch.tensor(new_v, dtype=torch.long)\n","    return inputs\n","\n","\n","# https://zenn.dev/hellorusk/articles/7fd588cae5b173\n","# huggingface Tokenizer の tokenize, encode, encode_plus などの違い\n","class TrainDataset(Dataset):\n","    def __init__(self, df, tokenizer, max_length, is_train=True):\n","        self.df = df\n","        self.tokenizer = tokenizer\n","        self.is_train = is_train\n","        self.max_length = max_length\n","        self.text = df[\"text\"].values\n","        \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, idx):   \n","        text = self.text[idx]\n","        inputs = prepare_input(str(text), self.tokenizer)\n","        ids = inputs[\"input_ids\"]\n","        mask = inputs[\"attention_mask\"]\n","        if self.is_train:\n","            label = self.df[CFG.target_col].values[idx]\n","            return {\n","                'ids': torch.tensor(ids, dtype=torch.long),\n","                'mask': torch.tensor(mask, dtype=torch.long),\n","                'label': torch.tensor(label, dtype=torch.float),\n","            }\n","        else:\n","            return {\n","                'ids': torch.tensor(ids, dtype=torch.long),\n","                'mask': torch.tensor(mask, dtype=torch.long),\n","            }\n","\n","# ====================================================\n","# LOSS\n","# ====================================================\n","\n","__CRITERIONS__ = {}\n","\n","def get_criterion():\n","    if hasattr(nn, CFG.loss_name):\n","        return nn.__getattribute__(CFG.loss_name)(**CFG.loss_params)\n","    elif __CRITERIONS__.get(CFG.loss_name) is not None:\n","        return __CRITERIONS__[CFG.loss_name](**CFG.loss_params)\n","    else:\n","        raise NotImplementedError\n","\n","# ====================================================\n","# Train\n","# ====================================================\n","\n","# Custom optimizer\n","__OPTIMIZERS__ = {}\n","\n","\n","def get_optimizer(model: nn.Module):\n","    optimizer_name = CFG.optimizer_name\n","    if __OPTIMIZERS__.get(optimizer_name) is not None:\n","        return __OPTIMIZERS__[optimizer_name](model.parameters(), **CFG.optimizer_params)\n","    else:\n","        return optim.__getattribute__(optimizer_name)(model.parameters(), **CFG.optimizer_params)\n","\n","def get_scheduler(cfg, optimizer, num_train_steps):\n","    if cfg.scheduler=='linear':\n","        scheduler = get_linear_schedule_with_warmup(\n","            optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","        )\n","    elif cfg.scheduler=='cosine':\n","        scheduler = get_cosine_schedule_with_warmup(\n","            optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","        )\n","    return scheduler\n","\n","class Model(nn.Module):\n","    def __init__(self, modelname_or_path):\n","        super(Model, self).__init__()\n","        self.base_model = AutoModel.from_pretrained(modelname_or_path)\n","        self.fc = nn.Linear(CFG.hidden_node, CFG.num_classes)\n","        self.dropout = nn.Dropout(p=0.)\n","        # self.ln = nn.LayerNorm(CFG.hidden_node)\n","        \n","    def feature(self, input_ids, attention_mask):\n","        outputs = self.base_model(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            output_hidden_states=False\n","        )\n","        last_hidden_states = outputs[0]\n","        feature = torch.mean(last_hidden_states, 1)\n","        return feature\n","\n","    def forward(self, input_ids, attention_mask=None):\n","        feature = self.feature(input_ids, attention_mask)\n","        output = self.fc(self.dropout(feature))\n","        return output\n","\n","\n","\n","\n","def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler,device):\n","    if CFG.use_amp:\n","        scaler = GradScaler()\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","    scores = AverageMeter()\n","    # switch to train mode\n","    model.train()\n","    start = end = time.time()\n","    for step, batch_data in enumerate(train_loader):\n","        # measure data loading time\n","        data_time.update(time.time() - end)\n","        ids = batch_data['ids'].to(device)\n","        mask = batch_data['mask'].to(device)\n","        label = batch_data['label'].to(device)\n","        batch_size = ids.size(0)\n","        if CFG.use_amp:\n","            with autocast():\n","                outputs = model(input_ids=ids, attention_mask=mask)\n","                loss = criterion(torch.squeeze(outputs), label)\n","        else:\n","            outputs = model(input_ids=ids, attention_mask=mask)\n","            loss = criterion(torch.squeeze(outputs), label)\n","        # record loss\n","        losses.update(loss.item(), batch_size)\n","        if CFG.use_amp:\n","            scaler.scale(loss).backward()\n","            scaler.step(optimizer)\n","            scaler.update()\n","        else:\n","            loss.backward()\n","            optimizer.step()\n","        optimizer.zero_grad()\n","        if scheduler is not None:\n","            scheduler.step()\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print(\n","                \"Epoch: [{0}][{1}/{2}] \"\n","                \"Data {data_time.val:.3f} ({data_time.avg:.3f}) \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                \"LR: {lr: 8f}\"\n","                .format(\n","                    epoch+1, step, len(train_loader), batch_time=batch_time,\n","                    data_time=data_time, loss=losses,\n","                    remain=timeSince(start, float(step+1)/len(train_loader)),\n","                    lr=scheduler.get_lr()[0]\n","                    )\n","                )\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    # switch to evaluation mode\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, batch_data in enumerate(valid_loader):\n","        # measure data loading time\n","        data_time.update(time.time() - end)\n","        ids = batch_data['ids'].to(device)\n","        mask = batch_data['mask'].to(device)\n","        batch_size = ids.size(0)\n","        # compute loss\n","        with torch.no_grad():\n","            outputs = model(input_ids=ids, attention_mask=mask)\n","        preds.append(outputs.to('cpu').numpy()) \n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print(\n","                \"EVAL: [{0}/{1}] \"\n","                \"Data {data_time.val:.3f} ({data_time.avg:.3f}) \"\n","                \"Elapsed {remain:s} \"\n","                .format(\n","                    step, len(valid_loader), batch_time=batch_time,\n","                    data_time=data_time,\n","                    remain=timeSince(start, float(step+1)/len(valid_loader)),\n","                    )\n","                )\n","    predictions = np.concatenate(preds)\n","    return predictions\n","\n","\n","def train_loop(folds, validation):\n","    validation_last = validation.copy()\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds.reset_index(drop=True)\n","    \n","    print(\"Text cleaning...\")\n","    train_folds['text'] = train_folds['comment_text'].progress_apply(text_cleaning)\n","    validation['less_toxic'] = validation['less_toxic'].progress_apply(text_cleaning)\n","    validation['more_toxic'] = validation['more_toxic'].progress_apply(text_cleaning)\n","    \n","    print(\"Train Shape:\", train_folds.shape)\n","    if CFG.under_sampling:\n","        print(\"Under Sampling\")\n","        train_folds_0 = train_folds[train_folds[\"target\"]==0]\n","        train_folds_0 = train_folds_0.sample(frac=CFG.under_sampling_ratio, random_state=CFG.seed)\n","        train_folds_1 = train_folds[train_folds[\"target\"]>0]\n","        train_folds = pd.concat([train_folds_1, train_folds_0], axis=0).reset_index(drop=True)\n","        print(\"Train Shape (After under sampling):\", train_folds.shape)\n","    \n","    validation_data = sorted(set(validation['less_toxic'].unique()) | set(validation['more_toxic'].unique()))\n","    validation_data = pd.DataFrame({'text': validation_data}).reset_index()\n","    print(\"Valid Shape:\", validation_data.shape)\n","    \n","    tokenizer = AutoTokenizer.from_pretrained(CFG.base_model_name)\n","        \n","    train_dataset = TrainDataset(train_folds, tokenizer, CFG.max_length, is_train=True)\n","    valid_dataset = TrainDataset(validation_data, tokenizer, CFG.max_length, is_train=False)\n","\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=CFG.batch_size, \n","        shuffle=True, \n","        num_workers=CFG.num_workers, \n","        pin_memory=True, \n","        drop_last=True\n","        )\n","    valid_loader = DataLoader(\n","        valid_dataset, \n","        batch_size=CFG.batch_size * 2, \n","        shuffle=False, \n","        num_workers=CFG.num_workers, \n","        pin_memory=True, \n","        drop_last=False\n","        )\n","    \n","\n","    # initialize\n","    model = Model(CFG.base_model_name)\n","    model.to(device)\n","    criterion = get_criterion()\n","\n","    optimizer = get_optimizer(model)\n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    CFG.num_warmup_steps=num_train_steps*CFG.num_warmup_steps_ratio\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","    # scheduler = get_scheduler(optimizer)\n","    best_score = 0\n","    best_loss = np.inf\n","\n","    for epoch in range(CFG.start_epoch, CFG.start_epoch + CFG.epochs):\n","        start_time = time.time()\n","        # train\n","        avg_loss = train_fn(\n","            train_loader, \n","            model, \n","            criterion,\n","            optimizer, \n","            epoch, \n","            scheduler,\n","            device,\n","            )\n","        \n","\n","        # eval\n","        preds = valid_fn(\n","            valid_loader,\n","            model,\n","            criterion, \n","            device\n","            )\n","\n","        # scoring\n","        validation_data[\"pred\"] = preds\n","\n","        if 'less_toxic_preds' in validation.columns:\n","            validation = validation.drop(columns='less_toxic_preds')\n","        if 'more_toxic_preds' in validation.columns:\n","            validation = validation.drop(columns='more_toxic_preds')\n","        rename_cols = {\"text\": 'less_toxic', 'pred': 'less_toxic_preds'}\n","        validation_less = validation.merge(\n","            validation_data[[\"text\", \"pred\"]].rename(columns=rename_cols), \n","            on='less_toxic', \n","            how='left'\n","            )\n","        rename_cols = {\"text\": 'more_toxic', 'pred': 'more_toxic_preds'}\n","        validation_more = validation.merge(\n","            validation_data[[\"text\", \"pred\"]].rename(columns=rename_cols), \n","            on='more_toxic', \n","            how='left'\n","            )\n","\n","        rename_cols = {\"text\": 'less_toxic', 'pred': 'less_toxic_preds'}\n","        validation = validation.merge(\n","            validation_data[[\"text\", 'pred']].rename(columns=rename_cols), \n","            on='less_toxic', \n","            how='left'\n","            )\n","        rename_cols = {\"text\": 'more_toxic', 'pred': 'more_toxic_preds'}\n","        validation = validation.merge(\n","            validation_data[[\"text\", 'pred']].rename(columns=rename_cols), \n","            on='more_toxic', \n","            how='left'\n","            )\n","\n","        # scoring\n","        score = get_result(validation)\n","\n","        elapsed = time.time() - start_time\n","        LOGGER.info(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  time: {elapsed:.0f}s\")\n","        LOGGER.info(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n","\n","        if score > best_score:\n","            best_score = score\n","            LOGGER.info(f\"Epoch {epoch+1} - Save : {score:.4f} Model\")\n","            torch.save({\"model\": model.state_dict()},\n","                        OUTPUT_DIR+'multilingual-toxic-xlm-roberta_best_score.pth')\n","            validation_last[\"more_toxic_preds\"] = validation[\"more_toxic_preds\"]\n","            validation_last[\"less_toxic_preds\"] = validation[\"less_toxic_preds\"]\n","    return validation_last, validation_less, validation_more\n","\n","\n","def main():\n","    seed_torch(seed=CFG.seed)\n","    train, validation_data, test, sub = read_processed_data()\n","    if CFG.debug:\n","        CFG.epochs = 1\n","        train = train.sample(n=1000, random_state=CFG.seed).reset_index(drop=True)\n","    oof_df = validation_data.copy()\n","    if CFG.train:\n","        # train \n","        oof_more_toxic = np.zeros(len(validation_data))\n","        oof_less_toxic = np.zeros(len(validation_data))\n","        _oof_df, validation_less, validation_more = train_loop(train, validation_data)\n","        oof_more_toxic += (_oof_df[\"more_toxic_preds\"].values)\n","        oof_less_toxic += (_oof_df[\"less_toxic_preds\"].values)\n","        get_result(_oof_df)\n","        # CV result\n","        LOGGER.info(f\"========== CV ==========\")\n","        oof_df[\"more_toxic_preds\"] = oof_more_toxic\n","        oof_df[\"less_toxic_preds\"] = oof_less_toxic\n","        get_result(oof_df)\n","        # save result\n","        validation_less.to_csv(OUTPUT_DIR+\"less_df.csv\", index=False)\n","        validation_more.to_csv(OUTPUT_DIR+\"more_df.csv\", index=False)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["795f987811454ee3a2c0224de68b61bf","36fc58d1030246d387f4963db4b4c1d6","26744ec4a4814490a2b6b25890ec8b01","7ba070589a7c48199cab9bc88c4ebd80","53f91566a2824d8780652ae523750386","97dcb0ca9e8242338e99c5c98c9c6b22","9113254db2fe436fbd9a39212348116c","f0b4f75f96df461cbf26c9a0bda60e35","62a59d3664a2411a9fd1cabec99e8b56","7994964c02f24b85bace1ab09bed6c33","916eed61cd26427b927486b396bf4082","af3186bef391493aa150e4b2c059c1ae","5c0d89c0169f467db1848d5bd35df62a","5575e0208d484de2b9f38c346bf06772","9e22cab924824846a9c469ef25a7f42e","787cedc8a9644ca6b27e3b84b3bc611b","62d831cfaad2419492c4dced69f5f8e7","527f52a21797403288bdfd39effc3b37","3637eef6e2a44d1798c7fc9cfe531e54","13293764b65e431a83145224316a669a","f2bc9c42aea1494da234a15c2acea1f9","7c86a9b79ec74329a6622a18bfbe2b1c","947e178b34214e8daf33936d02f234e5","508e710fdc824b5abea4670148b1aa07","832de0c0238b4f759ce5ec7a054fe1a6","3519635cdae64507832cc2244ff73633","30e6a03031a548d9821ad49ae9adc3ec","aa8cf84b385d4161bc0d67461ba2cbd6","18c8b8810e1944038401af37b514e4ac","b29652f3fb774157b9149f2f2b16e682","8fb52dd2f2d44dfd9e0dc83d931565eb","3adb92a7d52441bba2187219ac8b656d","cdc670a4c9fa406dafa6f7e473026ea3","17ae7630db904ab6b8809e861ccaf719","710a13db1410425784308168a2511a69","f09c65e2d6754bccbdf4f81e7a5c73a2","7592e2b5f3f74cb9ab6838e2a43bcef9","f9f36f2bbe2f4cd7a9d9b74ce3309678","6a071947768940028e3a3c2b36cd7510","588739ebee354702b3b9cc29fcc3e9fb","86178b974b8d4725bfa20426ee70c349","3e3031b3a8db4e9380607bc2feb8c94c","6465b09b5753494aa6e34585cb991e6e","4d7978edbd0f407299c23c38daf5c66a","900158f040a34893b6fff95e17608335","99b44d52d4aa4d45abb182a6a1ed751a","a20a9248206a45ec97df1e2989dcf655","6144854c24bf4a1b8b3ae8a856928a60","aac11dd6865f426a8374e8ea7ebbe115","e6dba378f6514b889e91d27ed8dfe8c3","4abc891d05f345fb9fa32ec646c62f50","adc1dd7637eb4773afe75940948c1f0a","8fa1bd1fa8b04cacb4c5661704625379","9bc44dac60394abfb492c0650429f17f","7248e778b59a4c5895aa84c47afed4f3","2b9c29e216ef44b99f2dc06bb45a2efc","77e586b10fad4db9b12ec2c0304073fa","bdf2a8713de54e77bddd86dded9e0830","718873656f7e44d8b84cc80047b93a67","2c1361aae01540428372581496f64a1c","10cde17b97054d2dab6608529195f9aa","f18f27f19c644ef5917dfde8f920a8fb","c51207431f3a40c3ac396245f2f0aeb6","f8a800f6fb644c6e88266bfec348369c","53cb2b28c6354849ae0314d9cdd537f6","d41bdb2269cf496284e0210ce1013eb8","f5f0d5c367884a4bb8973d51d7efaea7","e71fa4c824854898b19a3c865abbcdeb","19de70fba8a54a6c85b3f80afe98e7a7","7036b45db86546708bddcf6b1b348f1e","4ee2f6c67c534a95a229e9d5113d225e","905a5d20c26f44eb837a47598035bb75","757f1cdc8d5349678c1e25aa740b8b3b","62039c2f2ba5479bb5193fc9761a3aed","cb9ea8a7ba7342bc83fb5d89d46bfdc7","a2f86fbf2c414306936e66e9db7f1631","02eb21a1d640458385822b268f3b5ed5","8413f086de5c4c13b25a604a0e626cc8","581c1f2fb3d344cf85f2466b06fae04d","77b28a6fd8fe49578b4bd1221c2b8ea7","e89dd07958a040fda22e259803749d08","2b20040e57134ebc8d5b06456a5047fc","09660424d318405f9c9bd9b253f420d5","7f48474291d94b4c8096c5c9a2286169","ca59f9bb14be4261a9ea24007e017224","e8d5efa4ca054d42859ee0133ee30370","d5615f2eb3e74c6aa737ef7222ba6bec","e9dde50526ea4ff0bf3a1eabb545a947"]},"executionInfo":{"elapsed":13454783,"status":"ok","timestamp":1644143228117,"user":{"displayName":"棚橋直哉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07887718494945196844"},"user_tz":-540},"id":"h96LwBB3rk6J","outputId":"75e26695-ccb4-42c7-c05e-6df0cc2ad6a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["                 id  ... pseudo_label\n","0  0000997932d777bf  ...    -0.493725\n","1  000103f0d9cfb60f  ...    -0.636400\n","2  000113f07ec002fd  ...    -0.496514\n","3  0001b41b1c6bb37e  ...    -0.254959\n","4  0001d958c54c6e35  ...    -0.461024\n","\n","[5 rows x 9 columns]\n","Text cleaning...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"795f987811454ee3a2c0224de68b61bf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/215920 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af3186bef391493aa150e4b2c059c1ae","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/30108 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"947e178b34214e8daf33936d02f234e5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/30108 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Train Shape: (215920, 10)\n","Valid Shape: (14237, 2)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"17ae7630db904ab6b8809e861ccaf719","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/211 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"900158f040a34893b6fff95e17608335","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/635 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2b9c29e216ef44b99f2dc06bb45a2efc","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f5f0d5c367884a4bb8973d51d7efaea7","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8413f086de5c4c13b25a604a0e626cc8","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at unitary/multilingual-toxic-xlm-roberta were not used when initializing XLMRobertaModel: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaModel were not initialized from the model checkpoint at unitary/multilingual-toxic-xlm-roberta and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/3373] Data 1.486 (1.486) Elapsed 0m 2s (remain 134m 21s) Loss: 0.2020(0.2020) LR:  0.000000\n","Epoch: [1][100/3373] Data 0.000 (0.015) Elapsed 1m 19s (remain 43m 10s) Loss: 0.1128(0.1540) LR:  0.000001\n","Epoch: [1][200/3373] Data 0.000 (0.008) Elapsed 2m 37s (remain 41m 28s) Loss: 0.0459(0.1080) LR:  0.000001\n","Epoch: [1][300/3373] Data 0.000 (0.005) Elapsed 3m 55s (remain 40m 2s) Loss: 0.0292(0.0817) LR:  0.000002\n","Epoch: [1][400/3373] Data 0.000 (0.004) Elapsed 5m 13s (remain 38m 40s) Loss: 0.0090(0.0658) LR:  0.000002\n","Epoch: [1][500/3373] Data 0.000 (0.003) Elapsed 6m 30s (remain 37m 20s) Loss: 0.0134(0.0551) LR:  0.000003\n","Epoch: [1][600/3373] Data 0.000 (0.003) Elapsed 7m 48s (remain 36m 0s) Loss: 0.0085(0.0474) LR:  0.000004\n","Epoch: [1][700/3373] Data 0.000 (0.002) Elapsed 9m 6s (remain 34m 41s) Loss: 0.0062(0.0416) LR:  0.000004\n","Epoch: [1][800/3373] Data 0.000 (0.002) Elapsed 10m 23s (remain 33m 23s) Loss: 0.0072(0.0371) LR:  0.000005\n","Epoch: [1][900/3373] Data 0.000 (0.002) Elapsed 11m 41s (remain 32m 4s) Loss: 0.0047(0.0335) LR:  0.000005\n","Epoch: [1][1000/3373] Data 0.000 (0.002) Elapsed 12m 59s (remain 30m 46s) Loss: 0.0024(0.0306) LR:  0.000006\n","Epoch: [1][1100/3373] Data 0.000 (0.002) Elapsed 14m 16s (remain 29m 28s) Loss: 0.0032(0.0282) LR:  0.000007\n","Epoch: [1][1200/3373] Data 0.000 (0.001) Elapsed 15m 34s (remain 28m 10s) Loss: 0.0030(0.0262) LR:  0.000007\n","Epoch: [1][1300/3373] Data 0.000 (0.001) Elapsed 16m 52s (remain 26m 52s) Loss: 0.0041(0.0245) LR:  0.000008\n","Epoch: [1][1400/3373] Data 0.000 (0.001) Elapsed 18m 10s (remain 25m 34s) Loss: 0.0032(0.0229) LR:  0.000008\n","Epoch: [1][1500/3373] Data 0.000 (0.001) Elapsed 19m 27s (remain 24m 16s) Loss: 0.0030(0.0216) LR:  0.000009\n","Epoch: [1][1600/3373] Data 0.000 (0.001) Elapsed 20m 45s (remain 22m 58s) Loss: 0.0014(0.0205) LR:  0.000009\n","Epoch: [1][1700/3373] Data 0.000 (0.001) Elapsed 22m 3s (remain 21m 40s) Loss: 0.0023(0.0194) LR:  0.000010\n","Epoch: [1][1800/3373] Data 0.000 (0.001) Elapsed 23m 20s (remain 20m 22s) Loss: 0.0026(0.0185) LR:  0.000010\n","Epoch: [1][1900/3373] Data 0.000 (0.001) Elapsed 24m 38s (remain 19m 4s) Loss: 0.0031(0.0177) LR:  0.000010\n","Epoch: [1][2000/3373] Data 0.000 (0.001) Elapsed 25m 56s (remain 17m 47s) Loss: 0.0030(0.0169) LR:  0.000010\n","Epoch: [1][2100/3373] Data 0.000 (0.001) Elapsed 27m 13s (remain 16m 29s) Loss: 0.0023(0.0163) LR:  0.000010\n","Epoch: [1][2200/3373] Data 0.000 (0.001) Elapsed 28m 31s (remain 15m 11s) Loss: 0.0020(0.0156) LR:  0.000010\n","Epoch: [1][2300/3373] Data 0.000 (0.001) Elapsed 29m 49s (remain 13m 53s) Loss: 0.0020(0.0151) LR:  0.000010\n","Epoch: [1][2400/3373] Data 0.000 (0.001) Elapsed 31m 7s (remain 12m 35s) Loss: 0.0021(0.0146) LR:  0.000010\n","Epoch: [1][2500/3373] Data 0.000 (0.001) Elapsed 32m 24s (remain 11m 18s) Loss: 0.0031(0.0141) LR:  0.000010\n","Epoch: [1][2600/3373] Data 0.000 (0.001) Elapsed 33m 42s (remain 10m 0s) Loss: 0.0028(0.0136) LR:  0.000010\n","Epoch: [1][2700/3373] Data 0.000 (0.001) Elapsed 35m 0s (remain 8m 42s) Loss: 0.0018(0.0132) LR:  0.000010\n","Epoch: [1][2800/3373] Data 0.000 (0.001) Elapsed 36m 17s (remain 7m 24s) Loss: 0.0012(0.0128) LR:  0.000010\n","Epoch: [1][2900/3373] Data 0.000 (0.001) Elapsed 37m 35s (remain 6m 6s) Loss: 0.0013(0.0124) LR:  0.000010\n","Epoch: [1][3000/3373] Data 0.000 (0.001) Elapsed 38m 53s (remain 4m 49s) Loss: 0.0031(0.0121) LR:  0.000010\n","Epoch: [1][3100/3373] Data 0.000 (0.001) Elapsed 40m 10s (remain 3m 31s) Loss: 0.0011(0.0118) LR:  0.000010\n","Epoch: [1][3200/3373] Data 0.000 (0.001) Elapsed 41m 28s (remain 2m 13s) Loss: 0.0021(0.0115) LR:  0.000010\n","Epoch: [1][3300/3373] Data 0.000 (0.001) Elapsed 42m 46s (remain 0m 55s) Loss: 0.0034(0.0112) LR:  0.000010\n","Epoch: [1][3372/3373] Data 0.000 (0.001) Elapsed 43m 42s (remain 0m 0s) Loss: 0.0016(0.0110) LR:  0.000010\n","EVAL: [0/112] Data 0.790 (0.790) Elapsed 0m 1s (remain 2m 18s) \n","EVAL: [100/112] Data 0.000 (0.008) Elapsed 0m 47s (remain 0m 5s) \n","EVAL: [111/112] Data 0.000 (0.007) Elapsed 0m 51s (remain 0m 0s) \n"]},{"name":"stderr","output_type":"stream","text":["Score: 0.7162\n","Score: 0.7162\n","Epoch 1 - avg_train_loss: 0.0110  time: 2675s\n","Epoch 1 - avg_train_loss: 0.0110  time: 2675s\n","Epoch 1 - Score: 0.7162\n","Epoch 1 - Score: 0.7162\n","Epoch 1 - Save : 0.7162 Model\n","Epoch 1 - Save : 0.7162 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [2][0/3373] Data 0.643 (0.643) Elapsed 0m 1s (remain 80m 36s) Loss: 0.0043(0.0043) LR:  0.000010\n","Epoch: [2][100/3373] Data 0.000 (0.007) Elapsed 1m 19s (remain 42m 44s) Loss: 0.0022(0.0021) LR:  0.000010\n","Epoch: [2][200/3373] Data 0.000 (0.003) Elapsed 2m 36s (remain 41m 15s) Loss: 0.0015(0.0020) LR:  0.000010\n","Epoch: [2][300/3373] Data 0.000 (0.002) Elapsed 3m 54s (remain 39m 53s) Loss: 0.0016(0.0021) LR:  0.000010\n","Epoch: [2][400/3373] Data 0.000 (0.002) Elapsed 5m 12s (remain 38m 34s) Loss: 0.0013(0.0021) LR:  0.000010\n","Epoch: [2][500/3373] Data 0.000 (0.001) Elapsed 6m 29s (remain 37m 15s) Loss: 0.0019(0.0021) LR:  0.000009\n","Epoch: [2][600/3373] Data 0.000 (0.001) Elapsed 7m 47s (remain 35m 57s) Loss: 0.0014(0.0021) LR:  0.000009\n","Epoch: [2][700/3373] Data 0.000 (0.001) Elapsed 9m 5s (remain 34m 38s) Loss: 0.0016(0.0021) LR:  0.000009\n","Epoch: [2][800/3373] Data 0.000 (0.001) Elapsed 10m 23s (remain 33m 20s) Loss: 0.0016(0.0021) LR:  0.000009\n","Epoch: [2][900/3373] Data 0.000 (0.001) Elapsed 11m 40s (remain 32m 2s) Loss: 0.0027(0.0021) LR:  0.000009\n","Epoch: [2][1000/3373] Data 0.000 (0.001) Elapsed 12m 58s (remain 30m 44s) Loss: 0.0023(0.0021) LR:  0.000009\n","Epoch: [2][1100/3373] Data 0.000 (0.001) Elapsed 14m 16s (remain 29m 26s) Loss: 0.0013(0.0021) LR:  0.000009\n","Epoch: [2][1200/3373] Data 0.000 (0.001) Elapsed 15m 33s (remain 28m 9s) Loss: 0.0014(0.0021) LR:  0.000009\n","Epoch: [2][1300/3373] Data 0.000 (0.001) Elapsed 16m 51s (remain 26m 51s) Loss: 0.0033(0.0021) LR:  0.000009\n","Epoch: [2][1400/3373] Data 0.000 (0.001) Elapsed 18m 9s (remain 25m 33s) Loss: 0.0011(0.0021) LR:  0.000009\n","Epoch: [2][1500/3373] Data 0.000 (0.001) Elapsed 19m 27s (remain 24m 15s) Loss: 0.0027(0.0021) LR:  0.000009\n","Epoch: [2][1600/3373] Data 0.000 (0.001) Elapsed 20m 44s (remain 22m 57s) Loss: 0.0010(0.0021) LR:  0.000009\n","Epoch: [2][1700/3373] Data 0.000 (0.001) Elapsed 22m 2s (remain 21m 40s) Loss: 0.0018(0.0020) LR:  0.000009\n","Epoch: [2][1800/3373] Data 0.000 (0.001) Elapsed 23m 20s (remain 20m 22s) Loss: 0.0017(0.0020) LR:  0.000009\n","Epoch: [2][1900/3373] Data 0.000 (0.001) Elapsed 24m 38s (remain 19m 4s) Loss: 0.0014(0.0020) LR:  0.000009\n","Epoch: [2][2000/3373] Data 0.000 (0.001) Elapsed 25m 55s (remain 17m 46s) Loss: 0.0015(0.0020) LR:  0.000009\n","Epoch: [2][2100/3373] Data 0.000 (0.000) Elapsed 27m 13s (remain 16m 28s) Loss: 0.0017(0.0020) LR:  0.000009\n","Epoch: [2][2200/3373] Data 0.000 (0.000) Elapsed 28m 31s (remain 15m 11s) Loss: 0.0019(0.0020) LR:  0.000008\n","Epoch: [2][2300/3373] Data 0.000 (0.000) Elapsed 29m 48s (remain 13m 53s) Loss: 0.0018(0.0020) LR:  0.000008\n","Epoch: [2][2400/3373] Data 0.000 (0.000) Elapsed 31m 6s (remain 12m 35s) Loss: 0.0041(0.0020) LR:  0.000008\n","Epoch: [2][2500/3373] Data 0.000 (0.000) Elapsed 32m 24s (remain 11m 17s) Loss: 0.0012(0.0020) LR:  0.000008\n","Epoch: [2][2600/3373] Data 0.000 (0.000) Elapsed 33m 42s (remain 10m 0s) Loss: 0.0012(0.0020) LR:  0.000008\n","Epoch: [2][2700/3373] Data 0.000 (0.000) Elapsed 34m 59s (remain 8m 42s) Loss: 0.0009(0.0020) LR:  0.000008\n","Epoch: [2][2800/3373] Data 0.000 (0.000) Elapsed 36m 17s (remain 7m 24s) Loss: 0.0012(0.0020) LR:  0.000008\n","Epoch: [2][2900/3373] Data 0.000 (0.000) Elapsed 37m 35s (remain 6m 6s) Loss: 0.0021(0.0020) LR:  0.000008\n","Epoch: [2][3000/3373] Data 0.000 (0.000) Elapsed 38m 52s (remain 4m 49s) Loss: 0.0041(0.0020) LR:  0.000008\n","Epoch: [2][3100/3373] Data 0.000 (0.000) Elapsed 40m 10s (remain 3m 31s) Loss: 0.0023(0.0020) LR:  0.000008\n","Epoch: [2][3200/3373] Data 0.000 (0.000) Elapsed 41m 28s (remain 2m 13s) Loss: 0.0017(0.0020) LR:  0.000008\n","Epoch: [2][3300/3373] Data 0.000 (0.000) Elapsed 42m 46s (remain 0m 55s) Loss: 0.0034(0.0020) LR:  0.000008\n","Epoch: [2][3372/3373] Data 0.000 (0.000) Elapsed 43m 41s (remain 0m 0s) Loss: 0.0014(0.0020) LR:  0.000008\n","EVAL: [0/112] Data 0.693 (0.693) Elapsed 0m 1s (remain 2m 8s) \n","EVAL: [100/112] Data 0.000 (0.007) Elapsed 0m 47s (remain 0m 5s) \n","EVAL: [111/112] Data 0.000 (0.006) Elapsed 0m 51s (remain 0m 0s) \n"]},{"name":"stderr","output_type":"stream","text":["Score: 0.7206\n","Score: 0.7206\n","Epoch 2 - avg_train_loss: 0.0020  time: 2674s\n","Epoch 2 - avg_train_loss: 0.0020  time: 2674s\n","Epoch 2 - Score: 0.7206\n","Epoch 2 - Score: 0.7206\n","Epoch 2 - Save : 0.7206 Model\n","Epoch 2 - Save : 0.7206 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [3][0/3373] Data 0.502 (0.502) Elapsed 0m 1s (remain 72m 14s) Loss: 0.0015(0.0015) LR:  0.000008\n","Epoch: [3][100/3373] Data 0.000 (0.005) Elapsed 1m 19s (remain 42m 39s) Loss: 0.0012(0.0018) LR:  0.000007\n","Epoch: [3][200/3373] Data 0.000 (0.003) Elapsed 2m 36s (remain 41m 13s) Loss: 0.0012(0.0017) LR:  0.000007\n","Epoch: [3][300/3373] Data 0.000 (0.002) Elapsed 3m 54s (remain 39m 52s) Loss: 0.0010(0.0017) LR:  0.000007\n","Epoch: [3][400/3373] Data 0.000 (0.001) Elapsed 5m 12s (remain 38m 33s) Loss: 0.0020(0.0018) LR:  0.000007\n","Epoch: [3][500/3373] Data 0.000 (0.001) Elapsed 6m 29s (remain 37m 15s) Loss: 0.0019(0.0018) LR:  0.000007\n","Epoch: [3][600/3373] Data 0.000 (0.001) Elapsed 7m 47s (remain 35m 56s) Loss: 0.0010(0.0018) LR:  0.000007\n","Epoch: [3][700/3373] Data 0.000 (0.001) Elapsed 9m 5s (remain 34m 38s) Loss: 0.0015(0.0018) LR:  0.000007\n","Epoch: [3][800/3373] Data 0.000 (0.001) Elapsed 10m 23s (remain 33m 20s) Loss: 0.0014(0.0018) LR:  0.000007\n","Epoch: [3][900/3373] Data 0.000 (0.001) Elapsed 11m 40s (remain 32m 2s) Loss: 0.0010(0.0018) LR:  0.000007\n","Epoch: [3][1000/3373] Data 0.000 (0.001) Elapsed 12m 58s (remain 30m 44s) Loss: 0.0013(0.0018) LR:  0.000007\n","Epoch: [3][1100/3373] Data 0.000 (0.001) Elapsed 14m 16s (remain 29m 26s) Loss: 0.0027(0.0018) LR:  0.000006\n","Epoch: [3][1200/3373] Data 0.000 (0.001) Elapsed 15m 33s (remain 28m 9s) Loss: 0.0034(0.0018) LR:  0.000006\n","Epoch: [3][1300/3373] Data 0.000 (0.001) Elapsed 16m 51s (remain 26m 51s) Loss: 0.0024(0.0018) LR:  0.000006\n","Epoch: [3][1400/3373] Data 0.000 (0.001) Elapsed 18m 9s (remain 25m 33s) Loss: 0.0013(0.0018) LR:  0.000006\n","Epoch: [3][1500/3373] Data 0.000 (0.001) Elapsed 19m 27s (remain 24m 15s) Loss: 0.0024(0.0017) LR:  0.000006\n","Epoch: [3][1600/3373] Data 0.000 (0.000) Elapsed 20m 44s (remain 22m 57s) Loss: 0.0013(0.0018) LR:  0.000006\n","Epoch: [3][1700/3373] Data 0.000 (0.000) Elapsed 22m 2s (remain 21m 40s) Loss: 0.0016(0.0017) LR:  0.000006\n","Epoch: [3][1800/3373] Data 0.000 (0.000) Elapsed 23m 20s (remain 20m 22s) Loss: 0.0010(0.0017) LR:  0.000006\n","Epoch: [3][1900/3373] Data 0.000 (0.000) Elapsed 24m 38s (remain 19m 4s) Loss: 0.0045(0.0017) LR:  0.000006\n","Epoch: [3][2000/3373] Data 0.000 (0.000) Elapsed 25m 55s (remain 17m 46s) Loss: 0.0037(0.0017) LR:  0.000006\n","Epoch: [3][2100/3373] Data 0.000 (0.000) Elapsed 27m 13s (remain 16m 28s) Loss: 0.0019(0.0017) LR:  0.000005\n","Epoch: [3][2200/3373] Data 0.000 (0.000) Elapsed 28m 31s (remain 15m 11s) Loss: 0.0021(0.0017) LR:  0.000005\n","Epoch: [3][2300/3373] Data 0.000 (0.000) Elapsed 29m 48s (remain 13m 53s) Loss: 0.0014(0.0017) LR:  0.000005\n","Epoch: [3][2400/3373] Data 0.000 (0.000) Elapsed 31m 6s (remain 12m 35s) Loss: 0.0010(0.0017) LR:  0.000005\n","Epoch: [3][2500/3373] Data 0.000 (0.000) Elapsed 32m 24s (remain 11m 17s) Loss: 0.0014(0.0017) LR:  0.000005\n","Epoch: [3][2600/3373] Data 0.000 (0.000) Elapsed 33m 42s (remain 10m 0s) Loss: 0.0014(0.0017) LR:  0.000005\n","Epoch: [3][2700/3373] Data 0.000 (0.000) Elapsed 34m 59s (remain 8m 42s) Loss: 0.0030(0.0017) LR:  0.000005\n","Epoch: [3][2800/3373] Data 0.000 (0.000) Elapsed 36m 17s (remain 7m 24s) Loss: 0.0019(0.0017) LR:  0.000005\n","Epoch: [3][2900/3373] Data 0.000 (0.000) Elapsed 37m 35s (remain 6m 6s) Loss: 0.0018(0.0017) LR:  0.000005\n","Epoch: [3][3000/3373] Data 0.000 (0.000) Elapsed 38m 53s (remain 4m 49s) Loss: 0.0008(0.0017) LR:  0.000005\n","Epoch: [3][3100/3373] Data 0.000 (0.000) Elapsed 40m 10s (remain 3m 31s) Loss: 0.0013(0.0017) LR:  0.000004\n","Epoch: [3][3200/3373] Data 0.000 (0.000) Elapsed 41m 28s (remain 2m 13s) Loss: 0.0019(0.0017) LR:  0.000004\n","Epoch: [3][3300/3373] Data 0.000 (0.000) Elapsed 42m 46s (remain 0m 55s) Loss: 0.0010(0.0017) LR:  0.000004\n","Epoch: [3][3372/3373] Data 0.000 (0.000) Elapsed 43m 42s (remain 0m 0s) Loss: 0.0009(0.0017) LR:  0.000004\n","EVAL: [0/112] Data 0.715 (0.715) Elapsed 0m 1s (remain 2m 10s) \n","EVAL: [100/112] Data 0.000 (0.007) Elapsed 0m 47s (remain 0m 5s) \n","EVAL: [111/112] Data 0.000 (0.007) Elapsed 0m 51s (remain 0m 0s) \n"]},{"name":"stderr","output_type":"stream","text":["Score: 0.7214\n","Score: 0.7214\n","Epoch 3 - avg_train_loss: 0.0017  time: 2675s\n","Epoch 3 - avg_train_loss: 0.0017  time: 2675s\n","Epoch 3 - Score: 0.7214\n","Epoch 3 - Score: 0.7214\n","Epoch 3 - Save : 0.7214 Model\n","Epoch 3 - Save : 0.7214 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [4][0/3373] Data 0.595 (0.595) Elapsed 0m 1s (remain 77m 53s) Loss: 0.0012(0.0012) LR:  0.000004\n","Epoch: [4][100/3373] Data 0.000 (0.006) Elapsed 1m 19s (remain 42m 43s) Loss: 0.0008(0.0016) LR:  0.000004\n","Epoch: [4][200/3373] Data 0.000 (0.003) Elapsed 2m 36s (remain 41m 15s) Loss: 0.0020(0.0016) LR:  0.000004\n","Epoch: [4][300/3373] Data 0.000 (0.002) Elapsed 3m 54s (remain 39m 54s) Loss: 0.0013(0.0016) LR:  0.000004\n","Epoch: [4][400/3373] Data 0.000 (0.002) Elapsed 5m 12s (remain 38m 34s) Loss: 0.0019(0.0015) LR:  0.000004\n","Epoch: [4][500/3373] Data 0.000 (0.001) Elapsed 6m 30s (remain 37m 15s) Loss: 0.0012(0.0015) LR:  0.000004\n","Epoch: [4][600/3373] Data 0.000 (0.001) Elapsed 7m 47s (remain 35m 57s) Loss: 0.0014(0.0015) LR:  0.000004\n","Epoch: [4][700/3373] Data 0.000 (0.001) Elapsed 9m 5s (remain 34m 39s) Loss: 0.0013(0.0015) LR:  0.000003\n","Epoch: [4][800/3373] Data 0.000 (0.001) Elapsed 10m 23s (remain 33m 21s) Loss: 0.0012(0.0015) LR:  0.000003\n","Epoch: [4][900/3373] Data 0.000 (0.001) Elapsed 11m 40s (remain 32m 3s) Loss: 0.0016(0.0015) LR:  0.000003\n","Epoch: [4][1000/3373] Data 0.000 (0.001) Elapsed 12m 58s (remain 30m 45s) Loss: 0.0014(0.0015) LR:  0.000003\n","Epoch: [4][1100/3373] Data 0.000 (0.001) Elapsed 14m 16s (remain 29m 27s) Loss: 0.0010(0.0015) LR:  0.000003\n","Epoch: [4][1200/3373] Data 0.000 (0.001) Elapsed 15m 34s (remain 28m 9s) Loss: 0.0009(0.0015) LR:  0.000003\n","Epoch: [4][1300/3373] Data 0.000 (0.001) Elapsed 16m 51s (remain 26m 51s) Loss: 0.0029(0.0015) LR:  0.000003\n","Epoch: [4][1400/3373] Data 0.000 (0.001) Elapsed 18m 9s (remain 25m 33s) Loss: 0.0024(0.0015) LR:  0.000003\n","Epoch: [4][1500/3373] Data 0.000 (0.001) Elapsed 19m 27s (remain 24m 15s) Loss: 0.0013(0.0015) LR:  0.000003\n","Epoch: [4][1600/3373] Data 0.000 (0.001) Elapsed 20m 45s (remain 22m 58s) Loss: 0.0033(0.0015) LR:  0.000003\n","Epoch: [4][1700/3373] Data 0.000 (0.001) Elapsed 22m 2s (remain 21m 40s) Loss: 0.0010(0.0015) LR:  0.000002\n","Epoch: [4][1800/3373] Data 0.000 (0.001) Elapsed 23m 20s (remain 20m 22s) Loss: 0.0015(0.0015) LR:  0.000002\n","Epoch: [4][1900/3373] Data 0.000 (0.001) Elapsed 24m 38s (remain 19m 4s) Loss: 0.0010(0.0015) LR:  0.000002\n","Epoch: [4][2000/3373] Data 0.000 (0.000) Elapsed 25m 56s (remain 17m 46s) Loss: 0.0031(0.0015) LR:  0.000002\n","Epoch: [4][2100/3373] Data 0.000 (0.000) Elapsed 27m 13s (remain 16m 29s) Loss: 0.0013(0.0015) LR:  0.000002\n","Epoch: [4][2200/3373] Data 0.000 (0.000) Elapsed 28m 31s (remain 15m 11s) Loss: 0.0013(0.0015) LR:  0.000002\n","Epoch: [4][2300/3373] Data 0.000 (0.000) Elapsed 29m 49s (remain 13m 53s) Loss: 0.0015(0.0015) LR:  0.000002\n","Epoch: [4][2400/3373] Data 0.000 (0.000) Elapsed 31m 6s (remain 12m 35s) Loss: 0.0018(0.0015) LR:  0.000002\n","Epoch: [4][2500/3373] Data 0.000 (0.000) Elapsed 32m 24s (remain 11m 18s) Loss: 0.0010(0.0015) LR:  0.000002\n","Epoch: [4][2600/3373] Data 0.000 (0.000) Elapsed 33m 42s (remain 10m 0s) Loss: 0.0007(0.0015) LR:  0.000002\n","Epoch: [4][2700/3373] Data 0.000 (0.000) Elapsed 35m 0s (remain 8m 42s) Loss: 0.0010(0.0015) LR:  0.000002\n","Epoch: [4][2800/3373] Data 0.000 (0.000) Elapsed 36m 17s (remain 7m 24s) Loss: 0.0008(0.0015) LR:  0.000002\n","Epoch: [4][2900/3373] Data 0.000 (0.000) Elapsed 37m 35s (remain 6m 6s) Loss: 0.0018(0.0015) LR:  0.000002\n","Epoch: [4][3000/3373] Data 0.000 (0.000) Elapsed 38m 53s (remain 4m 49s) Loss: 0.0018(0.0015) LR:  0.000001\n","Epoch: [4][3100/3373] Data 0.000 (0.000) Elapsed 40m 11s (remain 3m 31s) Loss: 0.0012(0.0015) LR:  0.000001\n","Epoch: [4][3200/3373] Data 0.000 (0.000) Elapsed 41m 28s (remain 2m 13s) Loss: 0.0014(0.0015) LR:  0.000001\n","Epoch: [4][3300/3373] Data 0.000 (0.000) Elapsed 42m 46s (remain 0m 55s) Loss: 0.0008(0.0015) LR:  0.000001\n","Epoch: [4][3372/3373] Data 0.000 (0.000) Elapsed 43m 42s (remain 0m 0s) Loss: 0.0024(0.0015) LR:  0.000001\n","EVAL: [0/112] Data 0.743 (0.743) Elapsed 0m 1s (remain 2m 13s) \n","EVAL: [100/112] Data 0.000 (0.008) Elapsed 0m 47s (remain 0m 5s) \n","EVAL: [111/112] Data 0.000 (0.007) Elapsed 0m 51s (remain 0m 0s) \n"]},{"name":"stderr","output_type":"stream","text":["Score: 0.7215\n","Score: 0.7215\n","Epoch 4 - avg_train_loss: 0.0015  time: 2675s\n","Epoch 4 - avg_train_loss: 0.0015  time: 2675s\n","Epoch 4 - Score: 0.7215\n","Epoch 4 - Score: 0.7215\n","Epoch 4 - Save : 0.7215 Model\n","Epoch 4 - Save : 0.7215 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [5][0/3373] Data 0.690 (0.690) Elapsed 0m 1s (remain 83m 27s) Loss: 0.0011(0.0011) LR:  0.000001\n","Epoch: [5][100/3373] Data 0.000 (0.007) Elapsed 1m 19s (remain 42m 46s) Loss: 0.0011(0.0015) LR:  0.000001\n","Epoch: [5][200/3373] Data 0.000 (0.004) Elapsed 2m 36s (remain 41m 16s) Loss: 0.0007(0.0014) LR:  0.000001\n","Epoch: [5][300/3373] Data 0.000 (0.002) Elapsed 3m 54s (remain 39m 55s) Loss: 0.0014(0.0014) LR:  0.000001\n","Epoch: [5][400/3373] Data 0.000 (0.002) Elapsed 5m 12s (remain 38m 35s) Loss: 0.0012(0.0014) LR:  0.000001\n","Epoch: [5][500/3373] Data 0.000 (0.002) Elapsed 6m 30s (remain 37m 16s) Loss: 0.0011(0.0014) LR:  0.000001\n","Epoch: [5][600/3373] Data 0.000 (0.001) Elapsed 7m 47s (remain 35m 57s) Loss: 0.0023(0.0014) LR:  0.000001\n","Epoch: [5][700/3373] Data 0.000 (0.001) Elapsed 9m 5s (remain 34m 39s) Loss: 0.0009(0.0014) LR:  0.000001\n","Epoch: [5][800/3373] Data 0.000 (0.001) Elapsed 10m 23s (remain 33m 21s) Loss: 0.0010(0.0014) LR:  0.000001\n","Epoch: [5][900/3373] Data 0.000 (0.001) Elapsed 11m 41s (remain 32m 3s) Loss: 0.0015(0.0014) LR:  0.000001\n","Epoch: [5][1000/3373] Data 0.000 (0.001) Elapsed 12m 58s (remain 30m 45s) Loss: 0.0019(0.0014) LR:  0.000001\n","Epoch: [5][1100/3373] Data 0.000 (0.001) Elapsed 14m 16s (remain 29m 27s) Loss: 0.0007(0.0014) LR:  0.000001\n","Epoch: [5][1200/3373] Data 0.000 (0.001) Elapsed 15m 34s (remain 28m 9s) Loss: 0.0013(0.0014) LR:  0.000000\n","Epoch: [5][1300/3373] Data 0.000 (0.001) Elapsed 16m 51s (remain 26m 51s) Loss: 0.0007(0.0014) LR:  0.000000\n","Epoch: [5][1400/3373] Data 0.000 (0.001) Elapsed 18m 9s (remain 25m 33s) Loss: 0.0013(0.0014) LR:  0.000000\n","Epoch: [5][1500/3373] Data 0.000 (0.001) Elapsed 19m 27s (remain 24m 15s) Loss: 0.0024(0.0014) LR:  0.000000\n","Epoch: [5][1600/3373] Data 0.000 (0.001) Elapsed 20m 45s (remain 22m 58s) Loss: 0.0011(0.0014) LR:  0.000000\n","Epoch: [5][1700/3373] Data 0.000 (0.001) Elapsed 22m 2s (remain 21m 40s) Loss: 0.0014(0.0014) LR:  0.000000\n","Epoch: [5][1800/3373] Data 0.000 (0.001) Elapsed 23m 20s (remain 20m 22s) Loss: 0.0015(0.0014) LR:  0.000000\n","Epoch: [5][1900/3373] Data 0.000 (0.001) Elapsed 24m 38s (remain 19m 4s) Loss: 0.0013(0.0014) LR:  0.000000\n","Epoch: [5][2000/3373] Data 0.000 (0.001) Elapsed 25m 55s (remain 17m 46s) Loss: 0.0009(0.0014) LR:  0.000000\n","Epoch: [5][2100/3373] Data 0.000 (0.001) Elapsed 27m 13s (remain 16m 29s) Loss: 0.0010(0.0014) LR:  0.000000\n","Epoch: [5][2200/3373] Data 0.000 (0.000) Elapsed 28m 31s (remain 15m 11s) Loss: 0.0009(0.0014) LR:  0.000000\n","Epoch: [5][2300/3373] Data 0.000 (0.000) Elapsed 29m 49s (remain 13m 53s) Loss: 0.0011(0.0014) LR:  0.000000\n","Epoch: [5][2400/3373] Data 0.000 (0.000) Elapsed 31m 6s (remain 12m 35s) Loss: 0.0009(0.0014) LR:  0.000000\n","Epoch: [5][2500/3373] Data 0.000 (0.000) Elapsed 32m 24s (remain 11m 18s) Loss: 0.0016(0.0014) LR:  0.000000\n","Epoch: [5][2600/3373] Data 0.000 (0.000) Elapsed 33m 42s (remain 10m 0s) Loss: 0.0008(0.0014) LR:  0.000000\n","Epoch: [5][2700/3373] Data 0.000 (0.000) Elapsed 35m 0s (remain 8m 42s) Loss: 0.0018(0.0014) LR:  0.000000\n","Epoch: [5][2800/3373] Data 0.000 (0.000) Elapsed 36m 17s (remain 7m 24s) Loss: 0.0008(0.0014) LR:  0.000000\n","Epoch: [5][2900/3373] Data 0.000 (0.000) Elapsed 37m 35s (remain 6m 6s) Loss: 0.0013(0.0014) LR:  0.000000\n","Epoch: [5][3000/3373] Data 0.000 (0.000) Elapsed 38m 53s (remain 4m 49s) Loss: 0.0015(0.0014) LR:  0.000000\n","Epoch: [5][3100/3373] Data 0.000 (0.000) Elapsed 40m 10s (remain 3m 31s) Loss: 0.0019(0.0014) LR:  0.000000\n","Epoch: [5][3200/3373] Data 0.000 (0.000) Elapsed 41m 28s (remain 2m 13s) Loss: 0.0009(0.0014) LR:  0.000000\n","Epoch: [5][3300/3373] Data 0.000 (0.000) Elapsed 42m 46s (remain 0m 55s) Loss: 0.0007(0.0014) LR:  0.000000\n","Epoch: [5][3372/3373] Data 0.000 (0.000) Elapsed 43m 42s (remain 0m 0s) Loss: 0.0007(0.0014) LR:  0.000000\n","EVAL: [0/112] Data 0.750 (0.750) Elapsed 0m 1s (remain 2m 14s) \n","EVAL: [100/112] Data 0.000 (0.008) Elapsed 0m 47s (remain 0m 5s) \n","EVAL: [111/112] Data 0.000 (0.007) Elapsed 0m 51s (remain 0m 0s) \n"]},{"name":"stderr","output_type":"stream","text":["Score: 0.7219\n","Score: 0.7219\n","Epoch 5 - avg_train_loss: 0.0014  time: 2675s\n","Epoch 5 - avg_train_loss: 0.0014  time: 2675s\n","Epoch 5 - Score: 0.7219\n","Epoch 5 - Score: 0.7219\n","Epoch 5 - Save : 0.7219 Model\n","Epoch 5 - Save : 0.7219 Model\n","Score: 0.7219\n","Score: 0.7219\n","========== CV ==========\n","========== CV ==========\n","Score: 0.7219\n","Score: 0.7219\n"]}],"source":["if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VWsjoW2kvOvm"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":1885,"status":"ok","timestamp":1644143230361,"user":{"displayName":"棚橋直哉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07887718494945196844"},"user_tz":-540},"id":"RM2e9CqhDwMA"},"outputs":[],"source":["import os\n","import sys\n","import numpy as np\n","import pandas as pd\n","import math\n","import time\n","import random\n","import shutil\n","import copy\n","import collections\n","from pathlib import Path\n","from contextlib import contextmanager\n","from collections import defaultdict, Counter\n","from sklearn import preprocessing\n","from sklearn.metrics import roc_auc_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","from tqdm.auto import tqdm\n","from functools import partial\n","import torch\n","import torch.nn as nn\n","from torch.nn import MarginRankingLoss\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import Adam, SGD\n","import torchvision.models as models\n","from torch.nn.parameter import Parameter\n","from torch.utils.data import DataLoader, Dataset\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","import transformers\n","from transformers import (AutoModel, AutoTokenizer)\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","from torch.cuda.amp import autocast, GradScaler\n","import re\n","from bs4 import BeautifulSoup\n","tqdm.pandas()\n","\n","device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    ######################\n","    # Globals #\n","    ######################\n","    debug = False\n","    exp_name = \"exp4001_seed1\"\n","    fold_seed = 0\n","    seed = 1\n","    start_epoch = 0\n","    epochs = 5\n","    train = True\n","    folds = [0,1,2,3,4]\n","    n_fold = 5\n","    print_freq = 100\n","    use_amp = True\n","    target_col = \"pseudo_label\"\n","    ######################\n","    # Dataset #\n","    ######################\n","    head = 64\n","    tail = 64\n","    max_length = head+tail\n","    under_sampling = False\n","    under_sampling_ratio = 0.1\n","    ######################\n","    # Augmentation #\n","    ######################\n","\n","    ######################\n","    # Loaders #\n","    ######################\n","    batch_size = 64\n","    num_workers = 8\n","    ######################\n","    # Model #\n","    ######################\n","    # https://huggingface.co/deepset/xlm-roberta-base-squad2\n","    base_model_name = \"unitary/multilingual-toxic-xlm-roberta\"\n","    pretrained = True\n","    num_classes = 1  # Binary \n","    hidden_node = 768  # large: 1024, base: 768\n","    ######################\n","    # Criterion #\n","    ######################\n","    loss_name = \"MSELoss\"\n","    loss_params: dict = {}\n","    ######################\n","    # Optimizer #\n","    ######################\n","    optimizer_name = \"AdamW\"\n","    optimizer_params = {\n","        \"lr\": 1e-5,\n","    }\n","    ######################\n","    # Scheduler #\n","    ######################\n","    scheduler = \"cosine\"\n","    num_cycles=0.5\n","    num_warmup_steps_ratio = 0.1\n","    \n","\n","# ====================================================\n","# Directory settings\n","# ====================================================\n","INPUT_PATH = \"../input/\"\n","OUTPUT_DIR = f'../output/{CFG.exp_name}/' \n","if not os.path.exists(OUTPUT_DIR):\n","    os.makedirs(OUTPUT_DIR)\n","\n","\n","# ====================================================\n","# Utils\n","# ====================================================\n","\n","def seed_torch(seed=42):\n","    random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","\n","def init_logger(log_file=OUTPUT_DIR+\"train.log\"):\n","    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=log_file)\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","    \n","LOGGER = init_logger()\n","\n","def get_score(more_toxic_preds, less_toxic_preds):\n","    score = np.mean(more_toxic_preds > less_toxic_preds)\n","    return score\n","\n","\n","\n","def get_result(df):\n","    more_toxic_preds = df[\"more_toxic_preds\"].values\n","    less_toxic_preds = df[\"less_toxic_preds\"].values\n","    score = get_score(more_toxic_preds, less_toxic_preds)\n","    LOGGER.info(f\"Score: {score:<.4f}\")\n","    return score\n","\n","\n","def read_processed_data():\n","    validation_data = pd.read_csv(INPUT_PATH + \"validation_data.csv\")\n","    test = pd.read_csv(INPUT_PATH + \"comments_to_score.csv\")\n","    sub = pd.read_csv(INPUT_PATH + \"sample_submission.csv\")\n","    train_src = pd.read_csv(\"../input/jigsaw_1st/PseudoLabelDataset.csv\")\n","    val_comment_unq = pd.concat([validation_data['less_toxic'], validation_data['more_toxic']]).unique()\n","    train2017 = train_src[~train_src['comment_text'].isin(val_comment_unq)]\n","    print(train2017.head())\n","    return train2017, validation_data, test, sub\n","\n","\n","def text_cleaning(text):\n","    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n","    text = template.sub(r'', text)\n","    template = re.compile(r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\") #Removes e-mail address\n","    text = template.sub(r'.', text)\n","    # text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n","    ipPattern = re.compile('\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}') # Removes IP address\n","    text = ipPattern.sub(r'', text)\n","    text = text.replace('\\n','')\n","    text = text.strip() # remove spaces at the beginning and at the end of string\n","    return text\n","\n","# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n","\n","\n","def prepare_input(text, tokenizer):\n","    if CFG.tail == 0:\n","        inputs = tokenizer.encode_plus(\n","            text, \n","            return_tensors=None, \n","            add_special_tokens=True, \n","            max_length=CFG.max_length,\n","            pad_to_max_length=True,\n","            truncation=True\n","            )\n","        for k, v in inputs.items():\n","            inputs[k] = torch.tensor(v, dtype=torch.long)\n","    else:\n","        inputs = tokenizer.encode_plus(\n","            text,\n","            return_tensors=None, \n","            add_special_tokens=True, \n","            truncation=True\n","            )\n","        for k, v in inputs.items():\n","            v_length = len(v)\n","            if v_length > CFG.max_length:\n","                v = np.hstack([v[:CFG.head], v[-CFG.tail:]])\n","            if k == 'input_ids':\n","                new_v = np.ones(CFG.max_length) * tokenizer.pad_token_id\n","            else:\n","                new_v = np.zeros(CFG.max_length)\n","            new_v[:v_length] = v \n","            inputs[k] = torch.tensor(new_v, dtype=torch.long)\n","    return inputs\n","\n","\n","# https://zenn.dev/hellorusk/articles/7fd588cae5b173\n","# huggingface Tokenizer の tokenize, encode, encode_plus などの違い\n","class TrainDataset(Dataset):\n","    def __init__(self, df, tokenizer, max_length, is_train=True):\n","        self.df = df\n","        self.tokenizer = tokenizer\n","        self.is_train = is_train\n","        self.max_length = max_length\n","        self.text = df[\"text\"].values\n","        \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, idx):   \n","        text = self.text[idx]\n","        inputs = prepare_input(str(text), self.tokenizer)\n","        ids = inputs[\"input_ids\"]\n","        mask = inputs[\"attention_mask\"]\n","        if self.is_train:\n","            label = self.df[CFG.target_col].values[idx]\n","            return {\n","                'ids': torch.tensor(ids, dtype=torch.long),\n","                'mask': torch.tensor(mask, dtype=torch.long),\n","                'label': torch.tensor(label, dtype=torch.float),\n","            }\n","        else:\n","            return {\n","                'ids': torch.tensor(ids, dtype=torch.long),\n","                'mask': torch.tensor(mask, dtype=torch.long),\n","            }\n","\n","# ====================================================\n","# LOSS\n","# ====================================================\n","\n","__CRITERIONS__ = {}\n","\n","def get_criterion():\n","    if hasattr(nn, CFG.loss_name):\n","        return nn.__getattribute__(CFG.loss_name)(**CFG.loss_params)\n","    elif __CRITERIONS__.get(CFG.loss_name) is not None:\n","        return __CRITERIONS__[CFG.loss_name](**CFG.loss_params)\n","    else:\n","        raise NotImplementedError\n","\n","# ====================================================\n","# Train\n","# ====================================================\n","\n","# Custom optimizer\n","__OPTIMIZERS__ = {}\n","\n","\n","def get_optimizer(model: nn.Module):\n","    optimizer_name = CFG.optimizer_name\n","    if __OPTIMIZERS__.get(optimizer_name) is not None:\n","        return __OPTIMIZERS__[optimizer_name](model.parameters(), **CFG.optimizer_params)\n","    else:\n","        return optim.__getattribute__(optimizer_name)(model.parameters(), **CFG.optimizer_params)\n","\n","def get_scheduler(cfg, optimizer, num_train_steps):\n","    if cfg.scheduler=='linear':\n","        scheduler = get_linear_schedule_with_warmup(\n","            optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","        )\n","    elif cfg.scheduler=='cosine':\n","        scheduler = get_cosine_schedule_with_warmup(\n","            optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","        )\n","    return scheduler\n","\n","class Model(nn.Module):\n","    def __init__(self, modelname_or_path):\n","        super(Model, self).__init__()\n","        self.base_model = AutoModel.from_pretrained(modelname_or_path)\n","        self.fc = nn.Linear(CFG.hidden_node, CFG.num_classes)\n","        self.dropout = nn.Dropout(p=0.)\n","        # self.ln = nn.LayerNorm(CFG.hidden_node)\n","        \n","    def feature(self, input_ids, attention_mask):\n","        outputs = self.base_model(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            output_hidden_states=False\n","        )\n","        last_hidden_states = outputs[0]\n","        feature = torch.mean(last_hidden_states, 1)\n","        return feature\n","\n","    def forward(self, input_ids, attention_mask=None):\n","        feature = self.feature(input_ids, attention_mask)\n","        output = self.fc(self.dropout(feature))\n","        return output\n","\n","\n","\n","\n","def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler,device):\n","    if CFG.use_amp:\n","        scaler = GradScaler()\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","    scores = AverageMeter()\n","    # switch to train mode\n","    model.train()\n","    start = end = time.time()\n","    for step, batch_data in enumerate(train_loader):\n","        # measure data loading time\n","        data_time.update(time.time() - end)\n","        ids = batch_data['ids'].to(device)\n","        mask = batch_data['mask'].to(device)\n","        label = batch_data['label'].to(device)\n","        batch_size = ids.size(0)\n","        if CFG.use_amp:\n","            with autocast():\n","                outputs = model(input_ids=ids, attention_mask=mask)\n","                loss = criterion(torch.squeeze(outputs), label)\n","        else:\n","            outputs = model(input_ids=ids, attention_mask=mask)\n","            loss = criterion(torch.squeeze(outputs), label)\n","        # record loss\n","        losses.update(loss.item(), batch_size)\n","        if CFG.use_amp:\n","            scaler.scale(loss).backward()\n","            scaler.step(optimizer)\n","            scaler.update()\n","        else:\n","            loss.backward()\n","            optimizer.step()\n","        optimizer.zero_grad()\n","        if scheduler is not None:\n","            scheduler.step()\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print(\n","                \"Epoch: [{0}][{1}/{2}] \"\n","                \"Data {data_time.val:.3f} ({data_time.avg:.3f}) \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                \"LR: {lr: 8f}\"\n","                .format(\n","                    epoch+1, step, len(train_loader), batch_time=batch_time,\n","                    data_time=data_time, loss=losses,\n","                    remain=timeSince(start, float(step+1)/len(train_loader)),\n","                    lr=scheduler.get_lr()[0]\n","                    )\n","                )\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    # switch to evaluation mode\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, batch_data in enumerate(valid_loader):\n","        # measure data loading time\n","        data_time.update(time.time() - end)\n","        ids = batch_data['ids'].to(device)\n","        mask = batch_data['mask'].to(device)\n","        batch_size = ids.size(0)\n","        # compute loss\n","        with torch.no_grad():\n","            outputs = model(input_ids=ids, attention_mask=mask)\n","        preds.append(outputs.to('cpu').numpy()) \n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print(\n","                \"EVAL: [{0}/{1}] \"\n","                \"Data {data_time.val:.3f} ({data_time.avg:.3f}) \"\n","                \"Elapsed {remain:s} \"\n","                .format(\n","                    step, len(valid_loader), batch_time=batch_time,\n","                    data_time=data_time,\n","                    remain=timeSince(start, float(step+1)/len(valid_loader)),\n","                    )\n","                )\n","    predictions = np.concatenate(preds)\n","    return predictions\n","\n","\n","def train_loop(folds, validation):\n","    validation_last = validation.copy()\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds.reset_index(drop=True)\n","    \n","    print(\"Text cleaning...\")\n","    train_folds['text'] = train_folds['comment_text'].progress_apply(text_cleaning)\n","    validation['less_toxic'] = validation['less_toxic'].progress_apply(text_cleaning)\n","    validation['more_toxic'] = validation['more_toxic'].progress_apply(text_cleaning)\n","    \n","    print(\"Train Shape:\", train_folds.shape)\n","    if CFG.under_sampling:\n","        print(\"Under Sampling\")\n","        train_folds_0 = train_folds[train_folds[\"target\"]==0]\n","        train_folds_0 = train_folds_0.sample(frac=CFG.under_sampling_ratio, random_state=CFG.seed)\n","        train_folds_1 = train_folds[train_folds[\"target\"]>0]\n","        train_folds = pd.concat([train_folds_1, train_folds_0], axis=0).reset_index(drop=True)\n","        print(\"Train Shape (After under sampling):\", train_folds.shape)\n","    \n","    validation_data = sorted(set(validation['less_toxic'].unique()) | set(validation['more_toxic'].unique()))\n","    validation_data = pd.DataFrame({'text': validation_data}).reset_index()\n","    print(\"Valid Shape:\", validation_data.shape)\n","    \n","    tokenizer = AutoTokenizer.from_pretrained(CFG.base_model_name)\n","        \n","    train_dataset = TrainDataset(train_folds, tokenizer, CFG.max_length, is_train=True)\n","    valid_dataset = TrainDataset(validation_data, tokenizer, CFG.max_length, is_train=False)\n","\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=CFG.batch_size, \n","        shuffle=True, \n","        num_workers=CFG.num_workers, \n","        pin_memory=True, \n","        drop_last=True\n","        )\n","    valid_loader = DataLoader(\n","        valid_dataset, \n","        batch_size=CFG.batch_size * 2, \n","        shuffle=False, \n","        num_workers=CFG.num_workers, \n","        pin_memory=True, \n","        drop_last=False\n","        )\n","    \n","\n","    # initialize\n","    model = Model(CFG.base_model_name)\n","    model.to(device)\n","    criterion = get_criterion()\n","\n","    optimizer = get_optimizer(model)\n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    CFG.num_warmup_steps=num_train_steps*CFG.num_warmup_steps_ratio\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","    # scheduler = get_scheduler(optimizer)\n","    best_score = 0\n","    best_loss = np.inf\n","\n","    for epoch in range(CFG.start_epoch, CFG.start_epoch + CFG.epochs):\n","        start_time = time.time()\n","        # train\n","        avg_loss = train_fn(\n","            train_loader, \n","            model, \n","            criterion,\n","            optimizer, \n","            epoch, \n","            scheduler,\n","            device,\n","            )\n","        \n","\n","        # eval\n","        preds = valid_fn(\n","            valid_loader,\n","            model,\n","            criterion, \n","            device\n","            )\n","\n","        # scoring\n","        validation_data[\"pred\"] = preds\n","\n","        if 'less_toxic_preds' in validation.columns:\n","            validation = validation.drop(columns='less_toxic_preds')\n","        if 'more_toxic_preds' in validation.columns:\n","            validation = validation.drop(columns='more_toxic_preds')\n","        rename_cols = {\"text\": 'less_toxic', 'pred': 'less_toxic_preds'}\n","        validation_less = validation.merge(\n","            validation_data[[\"text\", \"pred\"]].rename(columns=rename_cols), \n","            on='less_toxic', \n","            how='left'\n","            )\n","        rename_cols = {\"text\": 'more_toxic', 'pred': 'more_toxic_preds'}\n","        validation_more = validation.merge(\n","            validation_data[[\"text\", \"pred\"]].rename(columns=rename_cols), \n","            on='more_toxic', \n","            how='left'\n","            )\n","\n","        rename_cols = {\"text\": 'less_toxic', 'pred': 'less_toxic_preds'}\n","        validation = validation.merge(\n","            validation_data[[\"text\", 'pred']].rename(columns=rename_cols), \n","            on='less_toxic', \n","            how='left'\n","            )\n","        rename_cols = {\"text\": 'more_toxic', 'pred': 'more_toxic_preds'}\n","        validation = validation.merge(\n","            validation_data[[\"text\", 'pred']].rename(columns=rename_cols), \n","            on='more_toxic', \n","            how='left'\n","            )\n","\n","        # scoring\n","        score = get_result(validation)\n","\n","        elapsed = time.time() - start_time\n","        LOGGER.info(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  time: {elapsed:.0f}s\")\n","        LOGGER.info(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n","\n","        if score > best_score:\n","            best_score = score\n","            LOGGER.info(f\"Epoch {epoch+1} - Save : {score:.4f} Model\")\n","            torch.save({\"model\": model.state_dict()},\n","                        OUTPUT_DIR+'multilingual-toxic-xlm-roberta_best_score.pth')\n","            validation_last[\"more_toxic_preds\"] = validation[\"more_toxic_preds\"]\n","            validation_last[\"less_toxic_preds\"] = validation[\"less_toxic_preds\"]\n","    return validation_last, validation_less, validation_more\n","\n","\n","def main():\n","    seed_torch(seed=CFG.seed)\n","    train, validation_data, test, sub = read_processed_data()\n","    if CFG.debug:\n","        CFG.epochs = 1\n","        train = train.sample(n=1000, random_state=CFG.seed).reset_index(drop=True)\n","    oof_df = validation_data.copy()\n","    if CFG.train:\n","        # train \n","        oof_more_toxic = np.zeros(len(validation_data))\n","        oof_less_toxic = np.zeros(len(validation_data))\n","        _oof_df, validation_less, validation_more = train_loop(train, validation_data)\n","        oof_more_toxic += (_oof_df[\"more_toxic_preds\"].values)\n","        oof_less_toxic += (_oof_df[\"less_toxic_preds\"].values)\n","        get_result(_oof_df)\n","        # CV result\n","        LOGGER.info(f\"========== CV ==========\")\n","        oof_df[\"more_toxic_preds\"] = oof_more_toxic\n","        oof_df[\"less_toxic_preds\"] = oof_less_toxic\n","        get_result(oof_df)\n","        # save result\n","        validation_less.to_csv(OUTPUT_DIR+\"less_df.csv\", index=False)\n","        validation_more.to_csv(OUTPUT_DIR+\"more_df.csv\", index=False)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["08d5018c177b4756961ffbdeda042316","8f4fa550afad4bc5827c04bd78f4c055","cbf77fd80f1e4a479b754f0487565b59","def3aa08969043c9b61f07e2a9e37dfb","ac944fecbf31477786aa6af6a29ce637","aa3e5e2c3cd04ef88745c1ddb0050f68","02fdd5f686834ac4afb37917167664b8","1e15472bcd974b7fae7fb8229d0dd6c5","59c1bbe003694ca8b8e83d43ab76412d","268443e43dfe4794ba4d6148bee647aa","3cb4e65b9c12446abe85c6ce4bf33083","e79346f1875646cfbdc663ed67a0116c","b0c9e412b0804cecb65d79802f145b0c","9684e5747a114f5cbb07c9726e1474b7","1425568c0382468bb61f119bc48fb9df","a7b28df5a69c4e9180407b69ce401670","7a0a76b480e54247a13db55dfe7aa7ff","96a975967267477e82c9acef191ed7c0","54a4bbf1c5a0492c8cdef33ece0ba62f","cc06fd1ed9254ed19ffa3ee17ee19a3c","843841274c7440509dc81f5c0c8704ab","0e640816150f4299a270528b6e2d1fc4","f58d97547cc1496781406b4e4c489dbd","58d9ca95e2f4423a9f2644750f2a80aa","2fba76e751d54632947059a42f1a9c04","fbad24901c8546be962a0d902059d90b","7c4cf013a912469b979028456747bfec","01f6debc355740e6a5ca47c93dc577ec","809bc09ffae84281a7503b9f0d3072e1","7fcacdfa272f4c36b0ee369f6024cc16","efa535b4c08c45f387fd217a7f6dcce3","ad22404aae404cec8928ec67b9bfb50f","bb1d769dfe194dda826f01f36b10379b"]},"executionInfo":{"elapsed":13415608,"status":"ok","timestamp":1644156645964,"user":{"displayName":"棚橋直哉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07887718494945196844"},"user_tz":-540},"id":"OvkfKYokj_AE","outputId":"c2243391-5fc8-4720-f2f2-13fb103e845d"},"outputs":[{"name":"stdout","output_type":"stream","text":["                 id  ... pseudo_label\n","0  0000997932d777bf  ...    -0.493725\n","1  000103f0d9cfb60f  ...    -0.636400\n","2  000113f07ec002fd  ...    -0.496514\n","3  0001b41b1c6bb37e  ...    -0.254959\n","4  0001d958c54c6e35  ...    -0.461024\n","\n","[5 rows x 9 columns]\n","Text cleaning...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"08d5018c177b4756961ffbdeda042316","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/215920 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e79346f1875646cfbdc663ed67a0116c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/30108 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f58d97547cc1496781406b4e4c489dbd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/30108 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Train Shape: (215920, 10)\n","Valid Shape: (14237, 2)\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at unitary/multilingual-toxic-xlm-roberta were not used when initializing XLMRobertaModel: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaModel were not initialized from the model checkpoint at unitary/multilingual-toxic-xlm-roberta and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/3373] Data 0.614 (0.614) Elapsed 0m 1s (remain 79m 1s) Loss: 0.0638(0.0638) LR:  0.000000\n","Epoch: [1][100/3373] Data 0.000 (0.006) Elapsed 1m 19s (remain 42m 41s) Loss: 0.0307(0.0462) LR:  0.000001\n","Epoch: [1][200/3373] Data 0.000 (0.003) Elapsed 2m 36s (remain 41m 14s) Loss: 0.0208(0.0363) LR:  0.000001\n","Epoch: [1][300/3373] Data 0.000 (0.002) Elapsed 3m 54s (remain 39m 52s) Loss: 0.0083(0.0291) LR:  0.000002\n","Epoch: [1][400/3373] Data 0.000 (0.002) Elapsed 5m 12s (remain 38m 33s) Loss: 0.0142(0.0239) LR:  0.000002\n","Epoch: [1][500/3373] Data 0.000 (0.001) Elapsed 6m 29s (remain 37m 15s) Loss: 0.0111(0.0203) LR:  0.000003\n","Epoch: [1][600/3373] Data 0.000 (0.001) Elapsed 7m 47s (remain 35m 56s) Loss: 0.0045(0.0178) LR:  0.000004\n","Epoch: [1][700/3373] Data 0.000 (0.001) Elapsed 9m 5s (remain 34m 38s) Loss: 0.0035(0.0158) LR:  0.000004\n","Epoch: [1][800/3373] Data 0.000 (0.001) Elapsed 10m 23s (remain 33m 20s) Loss: 0.0019(0.0143) LR:  0.000005\n","Epoch: [1][900/3373] Data 0.000 (0.001) Elapsed 11m 40s (remain 32m 2s) Loss: 0.0037(0.0131) LR:  0.000005\n","Epoch: [1][1000/3373] Data 0.000 (0.001) Elapsed 12m 58s (remain 30m 44s) Loss: 0.0024(0.0121) LR:  0.000006\n","Epoch: [1][1100/3373] Data 0.000 (0.001) Elapsed 14m 16s (remain 29m 26s) Loss: 0.0021(0.0113) LR:  0.000007\n","Epoch: [1][1200/3373] Data 0.000 (0.001) Elapsed 15m 33s (remain 28m 8s) Loss: 0.0016(0.0106) LR:  0.000007\n","Epoch: [1][1300/3373] Data 0.000 (0.001) Elapsed 16m 51s (remain 26m 51s) Loss: 0.0016(0.0100) LR:  0.000008\n","Epoch: [1][1400/3373] Data 0.000 (0.001) Elapsed 18m 9s (remain 25m 33s) Loss: 0.0033(0.0095) LR:  0.000008\n","Epoch: [1][1500/3373] Data 0.000 (0.001) Elapsed 19m 27s (remain 24m 15s) Loss: 0.0031(0.0090) LR:  0.000009\n","Epoch: [1][1600/3373] Data 0.000 (0.001) Elapsed 20m 44s (remain 22m 57s) Loss: 0.0025(0.0086) LR:  0.000009\n","Epoch: [1][1700/3373] Data 0.000 (0.001) Elapsed 22m 2s (remain 21m 39s) Loss: 0.0012(0.0082) LR:  0.000010\n","Epoch: [1][1800/3373] Data 0.000 (0.001) Elapsed 23m 20s (remain 20m 22s) Loss: 0.0052(0.0079) LR:  0.000010\n","Epoch: [1][1900/3373] Data 0.000 (0.000) Elapsed 24m 37s (remain 19m 4s) Loss: 0.0023(0.0076) LR:  0.000010\n","Epoch: [1][2000/3373] Data 0.000 (0.000) Elapsed 25m 55s (remain 17m 46s) Loss: 0.0079(0.0073) LR:  0.000010\n","Epoch: [1][2100/3373] Data 0.000 (0.000) Elapsed 27m 13s (remain 16m 28s) Loss: 0.0022(0.0071) LR:  0.000010\n","Epoch: [1][2200/3373] Data 0.000 (0.000) Elapsed 28m 31s (remain 15m 11s) Loss: 0.0030(0.0069) LR:  0.000010\n","Epoch: [1][2300/3373] Data 0.000 (0.000) Elapsed 29m 48s (remain 13m 53s) Loss: 0.0032(0.0067) LR:  0.000010\n","Epoch: [1][2400/3373] Data 0.000 (0.000) Elapsed 31m 6s (remain 12m 35s) Loss: 0.0014(0.0065) LR:  0.000010\n","Epoch: [1][2500/3373] Data 0.000 (0.000) Elapsed 32m 24s (remain 11m 17s) Loss: 0.0017(0.0063) LR:  0.000010\n","Epoch: [1][2600/3373] Data 0.000 (0.000) Elapsed 33m 41s (remain 10m 0s) Loss: 0.0045(0.0062) LR:  0.000010\n","Epoch: [1][2700/3373] Data 0.000 (0.000) Elapsed 34m 59s (remain 8m 42s) Loss: 0.0021(0.0060) LR:  0.000010\n","Epoch: [1][2800/3373] Data 0.000 (0.000) Elapsed 36m 17s (remain 7m 24s) Loss: 0.0017(0.0059) LR:  0.000010\n","Epoch: [1][2900/3373] Data 0.000 (0.000) Elapsed 37m 35s (remain 6m 6s) Loss: 0.0030(0.0058) LR:  0.000010\n","Epoch: [1][3000/3373] Data 0.000 (0.000) Elapsed 38m 52s (remain 4m 49s) Loss: 0.0015(0.0056) LR:  0.000010\n","Epoch: [1][3100/3373] Data 0.000 (0.000) Elapsed 40m 10s (remain 3m 31s) Loss: 0.0012(0.0055) LR:  0.000010\n","Epoch: [1][3200/3373] Data 0.000 (0.000) Elapsed 41m 28s (remain 2m 13s) Loss: 0.0022(0.0054) LR:  0.000010\n","Epoch: [1][3300/3373] Data 0.000 (0.000) Elapsed 42m 46s (remain 0m 55s) Loss: 0.0022(0.0053) LR:  0.000010\n","Epoch: [1][3372/3373] Data 0.000 (0.000) Elapsed 43m 42s (remain 0m 0s) Loss: 0.0019(0.0053) LR:  0.000010\n","EVAL: [0/112] Data 0.687 (0.687) Elapsed 0m 1s (remain 2m 7s) \n","EVAL: [100/112] Data 0.000 (0.007) Elapsed 0m 47s (remain 0m 5s) \n","EVAL: [111/112] Data 0.000 (0.006) Elapsed 0m 51s (remain 0m 0s) \n"]},{"name":"stderr","output_type":"stream","text":["Score: 0.7189\n","Score: 0.7189\n","Score: 0.7189\n","Epoch 1 - avg_train_loss: 0.0053  time: 2674s\n","Epoch 1 - avg_train_loss: 0.0053  time: 2674s\n","Epoch 1 - avg_train_loss: 0.0053  time: 2674s\n","Epoch 1 - Score: 0.7189\n","Epoch 1 - Score: 0.7189\n","Epoch 1 - Score: 0.7189\n","Epoch 1 - Save : 0.7189 Model\n","Epoch 1 - Save : 0.7189 Model\n","Epoch 1 - Save : 0.7189 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [2][0/3373] Data 0.583 (0.583) Elapsed 0m 1s (remain 77m 26s) Loss: 0.0014(0.0014) LR:  0.000010\n","Epoch: [2][100/3373] Data 0.000 (0.006) Elapsed 1m 19s (remain 42m 42s) Loss: 0.0032(0.0021) LR:  0.000010\n","Epoch: [2][200/3373] Data 0.000 (0.003) Elapsed 2m 36s (remain 41m 14s) Loss: 0.0017(0.0022) LR:  0.000010\n","Epoch: [2][300/3373] Data 0.000 (0.002) Elapsed 3m 54s (remain 39m 53s) Loss: 0.0034(0.0021) LR:  0.000010\n","Epoch: [2][400/3373] Data 0.000 (0.002) Elapsed 5m 12s (remain 38m 34s) Loss: 0.0016(0.0021) LR:  0.000010\n","Epoch: [2][500/3373] Data 0.000 (0.001) Elapsed 6m 29s (remain 37m 15s) Loss: 0.0017(0.0021) LR:  0.000009\n","Epoch: [2][600/3373] Data 0.000 (0.001) Elapsed 7m 47s (remain 35m 57s) Loss: 0.0047(0.0021) LR:  0.000009\n","Epoch: [2][700/3373] Data 0.000 (0.001) Elapsed 9m 5s (remain 34m 39s) Loss: 0.0026(0.0021) LR:  0.000009\n","Epoch: [2][800/3373] Data 0.000 (0.001) Elapsed 10m 23s (remain 33m 20s) Loss: 0.0016(0.0021) LR:  0.000009\n","Epoch: [2][900/3373] Data 0.000 (0.001) Elapsed 11m 40s (remain 32m 2s) Loss: 0.0026(0.0021) LR:  0.000009\n","Epoch: [2][1000/3373] Data 0.000 (0.001) Elapsed 12m 58s (remain 30m 45s) Loss: 0.0018(0.0021) LR:  0.000009\n","Epoch: [2][1100/3373] Data 0.000 (0.001) Elapsed 14m 16s (remain 29m 27s) Loss: 0.0030(0.0020) LR:  0.000009\n","Epoch: [2][1200/3373] Data 0.000 (0.001) Elapsed 15m 34s (remain 28m 9s) Loss: 0.0021(0.0020) LR:  0.000009\n","Epoch: [2][1300/3373] Data 0.000 (0.001) Elapsed 16m 51s (remain 26m 51s) Loss: 0.0015(0.0020) LR:  0.000009\n","Epoch: [2][1400/3373] Data 0.000 (0.001) Elapsed 18m 9s (remain 25m 33s) Loss: 0.0020(0.0020) LR:  0.000009\n","Epoch: [2][1500/3373] Data 0.000 (0.001) Elapsed 19m 27s (remain 24m 15s) Loss: 0.0014(0.0020) LR:  0.000009\n","Epoch: [2][1600/3373] Data 0.000 (0.001) Elapsed 20m 44s (remain 22m 57s) Loss: 0.0042(0.0020) LR:  0.000009\n","Epoch: [2][1700/3373] Data 0.000 (0.001) Elapsed 22m 2s (remain 21m 40s) Loss: 0.0027(0.0020) LR:  0.000009\n","Epoch: [2][1800/3373] Data 0.000 (0.000) Elapsed 23m 20s (remain 20m 22s) Loss: 0.0017(0.0020) LR:  0.000009\n","Epoch: [2][1900/3373] Data 0.000 (0.000) Elapsed 24m 38s (remain 19m 4s) Loss: 0.0028(0.0020) LR:  0.000009\n","Epoch: [2][2000/3373] Data 0.000 (0.000) Elapsed 25m 55s (remain 17m 46s) Loss: 0.0013(0.0020) LR:  0.000009\n","Epoch: [2][2100/3373] Data 0.000 (0.000) Elapsed 27m 13s (remain 16m 28s) Loss: 0.0020(0.0020) LR:  0.000009\n","Epoch: [2][2200/3373] Data 0.000 (0.000) Elapsed 28m 31s (remain 15m 11s) Loss: 0.0013(0.0020) LR:  0.000008\n","Epoch: [2][2300/3373] Data 0.000 (0.000) Elapsed 29m 48s (remain 13m 53s) Loss: 0.0015(0.0020) LR:  0.000008\n","Epoch: [2][2400/3373] Data 0.000 (0.000) Elapsed 31m 6s (remain 12m 35s) Loss: 0.0011(0.0020) LR:  0.000008\n","Epoch: [2][2500/3373] Data 0.000 (0.000) Elapsed 32m 24s (remain 11m 17s) Loss: 0.0016(0.0020) LR:  0.000008\n","Epoch: [2][2600/3373] Data 0.000 (0.000) Elapsed 33m 42s (remain 10m 0s) Loss: 0.0019(0.0020) LR:  0.000008\n","Epoch: [2][2700/3373] Data 0.000 (0.000) Elapsed 34m 59s (remain 8m 42s) Loss: 0.0017(0.0020) LR:  0.000008\n","Epoch: [2][2800/3373] Data 0.000 (0.000) Elapsed 36m 17s (remain 7m 24s) Loss: 0.0027(0.0020) LR:  0.000008\n","Epoch: [2][2900/3373] Data 0.000 (0.000) Elapsed 37m 35s (remain 6m 6s) Loss: 0.0014(0.0020) LR:  0.000008\n","Epoch: [2][3000/3373] Data 0.000 (0.000) Elapsed 38m 53s (remain 4m 49s) Loss: 0.0027(0.0020) LR:  0.000008\n","Epoch: [2][3100/3373] Data 0.000 (0.000) Elapsed 40m 10s (remain 3m 31s) Loss: 0.0011(0.0020) LR:  0.000008\n","Epoch: [2][3200/3373] Data 0.000 (0.000) Elapsed 41m 28s (remain 2m 13s) Loss: 0.0034(0.0020) LR:  0.000008\n","Epoch: [2][3300/3373] Data 0.000 (0.000) Elapsed 42m 46s (remain 0m 55s) Loss: 0.0013(0.0020) LR:  0.000008\n","Epoch: [2][3372/3373] Data 0.000 (0.000) Elapsed 43m 42s (remain 0m 0s) Loss: 0.0019(0.0020) LR:  0.000008\n","EVAL: [0/112] Data 0.655 (0.655) Elapsed 0m 1s (remain 2m 3s) \n","EVAL: [100/112] Data 0.000 (0.007) Elapsed 0m 47s (remain 0m 5s) \n","EVAL: [111/112] Data 0.000 (0.006) Elapsed 0m 51s (remain 0m 0s) \n"]},{"name":"stderr","output_type":"stream","text":["Score: 0.7201\n","Score: 0.7201\n","Score: 0.7201\n","Epoch 2 - avg_train_loss: 0.0020  time: 2675s\n","Epoch 2 - avg_train_loss: 0.0020  time: 2675s\n","Epoch 2 - avg_train_loss: 0.0020  time: 2675s\n","Epoch 2 - Score: 0.7201\n","Epoch 2 - Score: 0.7201\n","Epoch 2 - Score: 0.7201\n","Epoch 2 - Save : 0.7201 Model\n","Epoch 2 - Save : 0.7201 Model\n","Epoch 2 - Save : 0.7201 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [3][0/3373] Data 0.529 (0.529) Elapsed 0m 1s (remain 73m 57s) Loss: 0.0029(0.0029) LR:  0.000008\n","Epoch: [3][100/3373] Data 0.000 (0.005) Elapsed 1m 19s (remain 42m 40s) Loss: 0.0013(0.0016) LR:  0.000007\n","Epoch: [3][200/3373] Data 0.000 (0.003) Elapsed 2m 36s (remain 41m 14s) Loss: 0.0013(0.0017) LR:  0.000007\n","Epoch: [3][300/3373] Data 0.000 (0.002) Elapsed 3m 54s (remain 39m 53s) Loss: 0.0026(0.0016) LR:  0.000007\n","Epoch: [3][400/3373] Data 0.000 (0.001) Elapsed 5m 12s (remain 38m 33s) Loss: 0.0010(0.0017) LR:  0.000007\n","Epoch: [3][500/3373] Data 0.000 (0.001) Elapsed 6m 29s (remain 37m 15s) Loss: 0.0010(0.0017) LR:  0.000007\n","Epoch: [3][600/3373] Data 0.000 (0.001) Elapsed 7m 47s (remain 35m 56s) Loss: 0.0006(0.0017) LR:  0.000007\n","Epoch: [3][700/3373] Data 0.000 (0.001) Elapsed 9m 5s (remain 34m 38s) Loss: 0.0018(0.0017) LR:  0.000007\n","Epoch: [3][800/3373] Data 0.000 (0.001) Elapsed 10m 23s (remain 33m 20s) Loss: 0.0012(0.0017) LR:  0.000007\n","Epoch: [3][900/3373] Data 0.000 (0.001) Elapsed 11m 40s (remain 32m 2s) Loss: 0.0013(0.0017) LR:  0.000007\n","Epoch: [3][1000/3373] Data 0.000 (0.001) Elapsed 12m 58s (remain 30m 44s) Loss: 0.0013(0.0017) LR:  0.000007\n","Epoch: [3][1100/3373] Data 0.000 (0.001) Elapsed 14m 16s (remain 29m 26s) Loss: 0.0014(0.0017) LR:  0.000006\n","Epoch: [3][1200/3373] Data 0.000 (0.001) Elapsed 15m 33s (remain 28m 9s) Loss: 0.0011(0.0017) LR:  0.000006\n","Epoch: [3][1300/3373] Data 0.000 (0.001) Elapsed 16m 51s (remain 26m 51s) Loss: 0.0014(0.0017) LR:  0.000006\n","Epoch: [3][1400/3373] Data 0.000 (0.001) Elapsed 18m 9s (remain 25m 33s) Loss: 0.0032(0.0017) LR:  0.000006\n","Epoch: [3][1500/3373] Data 0.000 (0.001) Elapsed 19m 27s (remain 24m 15s) Loss: 0.0027(0.0017) LR:  0.000006\n","Epoch: [3][1600/3373] Data 0.000 (0.000) Elapsed 20m 44s (remain 22m 57s) Loss: 0.0022(0.0017) LR:  0.000006\n","Epoch: [3][1700/3373] Data 0.000 (0.000) Elapsed 22m 2s (remain 21m 40s) Loss: 0.0051(0.0017) LR:  0.000006\n","Epoch: [3][1800/3373] Data 0.000 (0.000) Elapsed 23m 20s (remain 20m 22s) Loss: 0.0013(0.0017) LR:  0.000006\n","Epoch: [3][1900/3373] Data 0.000 (0.000) Elapsed 24m 38s (remain 19m 4s) Loss: 0.0012(0.0017) LR:  0.000006\n","Epoch: [3][2000/3373] Data 0.000 (0.000) Elapsed 25m 55s (remain 17m 46s) Loss: 0.0034(0.0017) LR:  0.000006\n","Epoch: [3][2100/3373] Data 0.000 (0.000) Elapsed 27m 13s (remain 16m 28s) Loss: 0.0017(0.0017) LR:  0.000005\n","Epoch: [3][2200/3373] Data 0.000 (0.000) Elapsed 28m 31s (remain 15m 11s) Loss: 0.0013(0.0017) LR:  0.000005\n","Epoch: [3][2300/3373] Data 0.000 (0.000) Elapsed 29m 48s (remain 13m 53s) Loss: 0.0029(0.0017) LR:  0.000005\n","Epoch: [3][2400/3373] Data 0.000 (0.000) Elapsed 31m 6s (remain 12m 35s) Loss: 0.0020(0.0017) LR:  0.000005\n","Epoch: [3][2500/3373] Data 0.000 (0.000) Elapsed 32m 24s (remain 11m 17s) Loss: 0.0012(0.0016) LR:  0.000005\n","Epoch: [3][2600/3373] Data 0.000 (0.000) Elapsed 33m 42s (remain 10m 0s) Loss: 0.0011(0.0016) LR:  0.000005\n","Epoch: [3][2700/3373] Data 0.000 (0.000) Elapsed 34m 59s (remain 8m 42s) Loss: 0.0012(0.0016) LR:  0.000005\n","Epoch: [3][2800/3373] Data 0.000 (0.000) Elapsed 36m 17s (remain 7m 24s) Loss: 0.0027(0.0016) LR:  0.000005\n","Epoch: [3][2900/3373] Data 0.000 (0.000) Elapsed 37m 35s (remain 6m 6s) Loss: 0.0014(0.0016) LR:  0.000005\n","Epoch: [3][3000/3373] Data 0.000 (0.000) Elapsed 38m 53s (remain 4m 49s) Loss: 0.0013(0.0016) LR:  0.000005\n","Epoch: [3][3100/3373] Data 0.000 (0.000) Elapsed 40m 10s (remain 3m 31s) Loss: 0.0009(0.0016) LR:  0.000004\n","Epoch: [3][3200/3373] Data 0.000 (0.000) Elapsed 41m 28s (remain 2m 13s) Loss: 0.0014(0.0016) LR:  0.000004\n","Epoch: [3][3300/3373] Data 0.000 (0.000) Elapsed 42m 46s (remain 0m 55s) Loss: 0.0018(0.0016) LR:  0.000004\n","Epoch: [3][3372/3373] Data 0.000 (0.000) Elapsed 43m 42s (remain 0m 0s) Loss: 0.0014(0.0016) LR:  0.000004\n","EVAL: [0/112] Data 0.650 (0.650) Elapsed 0m 1s (remain 2m 3s) \n","EVAL: [100/112] Data 0.000 (0.007) Elapsed 0m 47s (remain 0m 5s) \n","EVAL: [111/112] Data 0.000 (0.006) Elapsed 0m 51s (remain 0m 0s) \n"]},{"name":"stderr","output_type":"stream","text":["Score: 0.7216\n","Score: 0.7216\n","Score: 0.7216\n","Epoch 3 - avg_train_loss: 0.0016  time: 2674s\n","Epoch 3 - avg_train_loss: 0.0016  time: 2674s\n","Epoch 3 - avg_train_loss: 0.0016  time: 2674s\n","Epoch 3 - Score: 0.7216\n","Epoch 3 - Score: 0.7216\n","Epoch 3 - Score: 0.7216\n","Epoch 3 - Save : 0.7216 Model\n","Epoch 3 - Save : 0.7216 Model\n","Epoch 3 - Save : 0.7216 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [4][0/3373] Data 0.631 (0.631) Elapsed 0m 1s (remain 79m 41s) Loss: 0.0011(0.0011) LR:  0.000004\n","Epoch: [4][100/3373] Data 0.000 (0.006) Elapsed 1m 19s (remain 42m 44s) Loss: 0.0011(0.0014) LR:  0.000004\n","Epoch: [4][200/3373] Data 0.000 (0.003) Elapsed 2m 36s (remain 41m 15s) Loss: 0.0006(0.0015) LR:  0.000004\n","Epoch: [4][300/3373] Data 0.000 (0.002) Elapsed 3m 54s (remain 39m 54s) Loss: 0.0010(0.0015) LR:  0.000004\n","Epoch: [4][400/3373] Data 0.000 (0.002) Elapsed 5m 12s (remain 38m 34s) Loss: 0.0024(0.0015) LR:  0.000004\n","Epoch: [4][500/3373] Data 0.000 (0.001) Elapsed 6m 30s (remain 37m 16s) Loss: 0.0012(0.0014) LR:  0.000004\n","Epoch: [4][600/3373] Data 0.000 (0.001) Elapsed 7m 47s (remain 35m 57s) Loss: 0.0013(0.0015) LR:  0.000004\n","Epoch: [4][700/3373] Data 0.000 (0.001) Elapsed 9m 5s (remain 34m 39s) Loss: 0.0017(0.0014) LR:  0.000003\n","Epoch: [4][800/3373] Data 0.000 (0.001) Elapsed 10m 23s (remain 33m 21s) Loss: 0.0011(0.0014) LR:  0.000003\n","Epoch: [4][900/3373] Data 0.000 (0.001) Elapsed 11m 40s (remain 32m 3s) Loss: 0.0016(0.0014) LR:  0.000003\n","Epoch: [4][1000/3373] Data 0.000 (0.001) Elapsed 12m 58s (remain 30m 45s) Loss: 0.0021(0.0014) LR:  0.000003\n","Epoch: [4][1100/3373] Data 0.000 (0.001) Elapsed 14m 16s (remain 29m 27s) Loss: 0.0014(0.0014) LR:  0.000003\n","Epoch: [4][1200/3373] Data 0.000 (0.001) Elapsed 15m 34s (remain 28m 9s) Loss: 0.0011(0.0014) LR:  0.000003\n","Epoch: [4][1300/3373] Data 0.000 (0.001) Elapsed 16m 51s (remain 26m 51s) Loss: 0.0011(0.0014) LR:  0.000003\n","Epoch: [4][1400/3373] Data 0.000 (0.001) Elapsed 18m 9s (remain 25m 33s) Loss: 0.0010(0.0014) LR:  0.000003\n","Epoch: [4][1500/3373] Data 0.000 (0.001) Elapsed 19m 27s (remain 24m 15s) Loss: 0.0024(0.0014) LR:  0.000003\n","Epoch: [4][1600/3373] Data 0.000 (0.001) Elapsed 20m 45s (remain 22m 58s) Loss: 0.0008(0.0014) LR:  0.000003\n","Epoch: [4][1700/3373] Data 0.000 (0.001) Elapsed 22m 2s (remain 21m 40s) Loss: 0.0006(0.0014) LR:  0.000002\n","Epoch: [4][1800/3373] Data 0.000 (0.001) Elapsed 23m 20s (remain 20m 22s) Loss: 0.0009(0.0014) LR:  0.000002\n","Epoch: [4][1900/3373] Data 0.000 (0.000) Elapsed 24m 38s (remain 19m 4s) Loss: 0.0013(0.0014) LR:  0.000002\n","Epoch: [4][2000/3373] Data 0.000 (0.000) Elapsed 25m 55s (remain 17m 46s) Loss: 0.0021(0.0014) LR:  0.000002\n","Epoch: [4][2100/3373] Data 0.000 (0.000) Elapsed 27m 13s (remain 16m 29s) Loss: 0.0012(0.0014) LR:  0.000002\n","Epoch: [4][2200/3373] Data 0.000 (0.000) Elapsed 28m 31s (remain 15m 11s) Loss: 0.0017(0.0014) LR:  0.000002\n","Epoch: [4][2300/3373] Data 0.000 (0.000) Elapsed 29m 49s (remain 13m 53s) Loss: 0.0007(0.0014) LR:  0.000002\n","Epoch: [4][2400/3373] Data 0.000 (0.000) Elapsed 31m 6s (remain 12m 35s) Loss: 0.0008(0.0014) LR:  0.000002\n","Epoch: [4][2500/3373] Data 0.000 (0.000) Elapsed 32m 24s (remain 11m 18s) Loss: 0.0016(0.0014) LR:  0.000002\n","Epoch: [4][2600/3373] Data 0.000 (0.000) Elapsed 33m 42s (remain 10m 0s) Loss: 0.0024(0.0014) LR:  0.000002\n","Epoch: [4][2700/3373] Data 0.000 (0.000) Elapsed 35m 0s (remain 8m 42s) Loss: 0.0034(0.0014) LR:  0.000002\n","Epoch: [4][2800/3373] Data 0.000 (0.000) Elapsed 36m 17s (remain 7m 24s) Loss: 0.0010(0.0014) LR:  0.000002\n","Epoch: [4][2900/3373] Data 0.000 (0.000) Elapsed 37m 35s (remain 6m 6s) Loss: 0.0010(0.0014) LR:  0.000002\n","Epoch: [4][3000/3373] Data 0.000 (0.000) Elapsed 38m 53s (remain 4m 49s) Loss: 0.0006(0.0014) LR:  0.000001\n","Epoch: [4][3100/3373] Data 0.000 (0.000) Elapsed 40m 10s (remain 3m 31s) Loss: 0.0011(0.0014) LR:  0.000001\n","Epoch: [4][3200/3373] Data 0.000 (0.000) Elapsed 41m 28s (remain 2m 13s) Loss: 0.0026(0.0014) LR:  0.000001\n","Epoch: [4][3300/3373] Data 0.000 (0.000) Elapsed 42m 46s (remain 0m 55s) Loss: 0.0011(0.0014) LR:  0.000001\n","Epoch: [4][3372/3373] Data 0.000 (0.000) Elapsed 43m 42s (remain 0m 0s) Loss: 0.0011(0.0014) LR:  0.000001\n","EVAL: [0/112] Data 0.614 (0.614) Elapsed 0m 1s (remain 1m 59s) \n","EVAL: [100/112] Data 0.000 (0.006) Elapsed 0m 47s (remain 0m 5s) \n","EVAL: [111/112] Data 0.000 (0.006) Elapsed 0m 51s (remain 0m 0s) \n"]},{"name":"stderr","output_type":"stream","text":["Score: 0.7217\n","Score: 0.7217\n","Score: 0.7217\n","Epoch 4 - avg_train_loss: 0.0014  time: 2675s\n","Epoch 4 - avg_train_loss: 0.0014  time: 2675s\n","Epoch 4 - avg_train_loss: 0.0014  time: 2675s\n","Epoch 4 - Score: 0.7217\n","Epoch 4 - Score: 0.7217\n","Epoch 4 - Score: 0.7217\n","Epoch 4 - Save : 0.7217 Model\n","Epoch 4 - Save : 0.7217 Model\n","Epoch 4 - Save : 0.7217 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [5][0/3373] Data 0.661 (0.661) Elapsed 0m 1s (remain 80m 55s) Loss: 0.0021(0.0021) LR:  0.000001\n","Epoch: [5][100/3373] Data 0.000 (0.007) Elapsed 1m 19s (remain 42m 44s) Loss: 0.0011(0.0013) LR:  0.000001\n","Epoch: [5][200/3373] Data 0.000 (0.003) Elapsed 2m 36s (remain 41m 15s) Loss: 0.0012(0.0014) LR:  0.000001\n","Epoch: [5][300/3373] Data 0.000 (0.002) Elapsed 3m 54s (remain 39m 54s) Loss: 0.0008(0.0013) LR:  0.000001\n","Epoch: [5][400/3373] Data 0.000 (0.002) Elapsed 5m 12s (remain 38m 35s) Loss: 0.0013(0.0013) LR:  0.000001\n","Epoch: [5][500/3373] Data 0.000 (0.001) Elapsed 6m 30s (remain 37m 16s) Loss: 0.0009(0.0013) LR:  0.000001\n","Epoch: [5][600/3373] Data 0.000 (0.001) Elapsed 7m 47s (remain 35m 57s) Loss: 0.0023(0.0013) LR:  0.000001\n","Epoch: [5][700/3373] Data 0.000 (0.001) Elapsed 9m 5s (remain 34m 39s) Loss: 0.0006(0.0013) LR:  0.000001\n","Epoch: [5][800/3373] Data 0.000 (0.001) Elapsed 10m 23s (remain 33m 21s) Loss: 0.0010(0.0013) LR:  0.000001\n","Epoch: [5][900/3373] Data 0.000 (0.001) Elapsed 11m 41s (remain 32m 3s) Loss: 0.0035(0.0013) LR:  0.000001\n","Epoch: [5][1000/3373] Data 0.000 (0.001) Elapsed 12m 58s (remain 30m 45s) Loss: 0.0018(0.0013) LR:  0.000001\n","Epoch: [5][1100/3373] Data 0.000 (0.001) Elapsed 14m 16s (remain 29m 27s) Loss: 0.0018(0.0013) LR:  0.000001\n","Epoch: [5][1200/3373] Data 0.000 (0.001) Elapsed 15m 34s (remain 28m 9s) Loss: 0.0017(0.0013) LR:  0.000000\n","Epoch: [5][1300/3373] Data 0.000 (0.001) Elapsed 16m 51s (remain 26m 51s) Loss: 0.0010(0.0013) LR:  0.000000\n","Epoch: [5][1400/3373] Data 0.000 (0.001) Elapsed 18m 9s (remain 25m 33s) Loss: 0.0006(0.0013) LR:  0.000000\n","Epoch: [5][1500/3373] Data 0.000 (0.001) Elapsed 19m 27s (remain 24m 15s) Loss: 0.0009(0.0013) LR:  0.000000\n","Epoch: [5][1600/3373] Data 0.000 (0.001) Elapsed 20m 45s (remain 22m 58s) Loss: 0.0007(0.0013) LR:  0.000000\n","Epoch: [5][1700/3373] Data 0.000 (0.001) Elapsed 22m 2s (remain 21m 40s) Loss: 0.0014(0.0013) LR:  0.000000\n","Epoch: [5][1800/3373] Data 0.000 (0.001) Elapsed 23m 20s (remain 20m 22s) Loss: 0.0016(0.0013) LR:  0.000000\n","Epoch: [5][1900/3373] Data 0.000 (0.001) Elapsed 24m 38s (remain 19m 4s) Loss: 0.0010(0.0013) LR:  0.000000\n","Epoch: [5][2000/3373] Data 0.000 (0.000) Elapsed 25m 55s (remain 17m 46s) Loss: 0.0026(0.0013) LR:  0.000000\n","Epoch: [5][2100/3373] Data 0.000 (0.000) Elapsed 27m 13s (remain 16m 29s) Loss: 0.0015(0.0013) LR:  0.000000\n","Epoch: [5][2200/3373] Data 0.000 (0.000) Elapsed 28m 31s (remain 15m 11s) Loss: 0.0026(0.0013) LR:  0.000000\n","Epoch: [5][2300/3373] Data 0.000 (0.000) Elapsed 29m 49s (remain 13m 53s) Loss: 0.0014(0.0013) LR:  0.000000\n","Epoch: [5][2400/3373] Data 0.000 (0.000) Elapsed 31m 6s (remain 12m 35s) Loss: 0.0021(0.0013) LR:  0.000000\n","Epoch: [5][2500/3373] Data 0.000 (0.000) Elapsed 32m 24s (remain 11m 17s) Loss: 0.0015(0.0013) LR:  0.000000\n","Epoch: [5][2600/3373] Data 0.000 (0.000) Elapsed 33m 42s (remain 10m 0s) Loss: 0.0019(0.0013) LR:  0.000000\n","Epoch: [5][2700/3373] Data 0.000 (0.000) Elapsed 34m 59s (remain 8m 42s) Loss: 0.0025(0.0013) LR:  0.000000\n","Epoch: [5][2800/3373] Data 0.000 (0.000) Elapsed 36m 17s (remain 7m 24s) Loss: 0.0009(0.0013) LR:  0.000000\n","Epoch: [5][2900/3373] Data 0.000 (0.000) Elapsed 37m 35s (remain 6m 6s) Loss: 0.0011(0.0013) LR:  0.000000\n","Epoch: [5][3000/3373] Data 0.000 (0.000) Elapsed 38m 52s (remain 4m 49s) Loss: 0.0010(0.0013) LR:  0.000000\n","Epoch: [5][3100/3373] Data 0.000 (0.000) Elapsed 40m 10s (remain 3m 31s) Loss: 0.0013(0.0013) LR:  0.000000\n","Epoch: [5][3200/3373] Data 0.000 (0.000) Elapsed 41m 28s (remain 2m 13s) Loss: 0.0009(0.0013) LR:  0.000000\n","Epoch: [5][3300/3373] Data 0.000 (0.000) Elapsed 42m 45s (remain 0m 55s) Loss: 0.0021(0.0013) LR:  0.000000\n","Epoch: [5][3372/3373] Data 0.000 (0.000) Elapsed 43m 41s (remain 0m 0s) Loss: 0.0008(0.0013) LR:  0.000000\n","EVAL: [0/112] Data 0.609 (0.609) Elapsed 0m 1s (remain 1m 59s) \n","EVAL: [100/112] Data 0.000 (0.006) Elapsed 0m 47s (remain 0m 5s) \n","EVAL: [111/112] Data 0.000 (0.006) Elapsed 0m 51s (remain 0m 0s) \n"]},{"name":"stderr","output_type":"stream","text":["Score: 0.7226\n","Score: 0.7226\n","Score: 0.7226\n","Epoch 5 - avg_train_loss: 0.0013  time: 2674s\n","Epoch 5 - avg_train_loss: 0.0013  time: 2674s\n","Epoch 5 - avg_train_loss: 0.0013  time: 2674s\n","Epoch 5 - Score: 0.7226\n","Epoch 5 - Score: 0.7226\n","Epoch 5 - Score: 0.7226\n","Epoch 5 - Save : 0.7226 Model\n","Epoch 5 - Save : 0.7226 Model\n","Epoch 5 - Save : 0.7226 Model\n","Score: 0.7226\n","Score: 0.7226\n","Score: 0.7226\n","========== CV ==========\n","========== CV ==========\n","========== CV ==========\n","Score: 0.7226\n","Score: 0.7226\n","Score: 0.7226\n"]}],"source":["if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6953,"status":"ok","timestamp":1644192670836,"user":{"displayName":"棚橋直哉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07887718494945196844"},"user_tz":-540},"id":"YoTbrLGuj_aB"},"outputs":[],"source":["import os\n","import sys\n","import numpy as np\n","import pandas as pd\n","import math\n","import time\n","import random\n","import shutil\n","import copy\n","import collections\n","from pathlib import Path\n","from contextlib import contextmanager\n","from collections import defaultdict, Counter\n","from sklearn import preprocessing\n","from sklearn.metrics import roc_auc_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","from tqdm.auto import tqdm\n","from functools import partial\n","import torch\n","import torch.nn as nn\n","from torch.nn import MarginRankingLoss\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import Adam, SGD\n","import torchvision.models as models\n","from torch.nn.parameter import Parameter\n","from torch.utils.data import DataLoader, Dataset\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","import transformers\n","from transformers import (AutoModel, AutoTokenizer)\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","from torch.cuda.amp import autocast, GradScaler\n","import re\n","from bs4 import BeautifulSoup\n","tqdm.pandas()\n","\n","device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    ######################\n","    # Globals #\n","    ######################\n","    debug = False\n","    exp_name = \"exp4001_seed2\"\n","    fold_seed = 0\n","    seed = 2\n","    start_epoch = 0\n","    epochs = 5\n","    train = True\n","    folds = [0,1,2,3,4]\n","    n_fold = 5\n","    print_freq = 100\n","    use_amp = True\n","    target_col = \"pseudo_label\"\n","    ######################\n","    # Dataset #\n","    ######################\n","    head = 64\n","    tail = 64\n","    max_length = head+tail\n","    under_sampling = False\n","    under_sampling_ratio = 0.1\n","    ######################\n","    # Augmentation #\n","    ######################\n","\n","    ######################\n","    # Loaders #\n","    ######################\n","    batch_size = 64\n","    num_workers = 8\n","    ######################\n","    # Model #\n","    ######################\n","    # https://huggingface.co/deepset/xlm-roberta-base-squad2\n","    base_model_name = \"unitary/multilingual-toxic-xlm-roberta\"\n","    pretrained = True\n","    num_classes = 1  # Binary \n","    hidden_node = 768  # large: 1024, base: 768\n","    ######################\n","    # Criterion #\n","    ######################\n","    loss_name = \"MSELoss\"\n","    loss_params: dict = {}\n","    ######################\n","    # Optimizer #\n","    ######################\n","    optimizer_name = \"AdamW\"\n","    optimizer_params = {\n","        \"lr\": 1e-5,\n","    }\n","    ######################\n","    # Scheduler #\n","    ######################\n","    scheduler = \"cosine\"\n","    num_cycles=0.5\n","    num_warmup_steps_ratio = 0.1\n","    \n","\n","# ====================================================\n","# Directory settings\n","# ====================================================\n","INPUT_PATH = \"../input/\"\n","OUTPUT_DIR = f'../output/{CFG.exp_name}/' \n","if not os.path.exists(OUTPUT_DIR):\n","    os.makedirs(OUTPUT_DIR)\n","\n","\n","# ====================================================\n","# Utils\n","# ====================================================\n","\n","def seed_torch(seed=42):\n","    random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","\n","def init_logger(log_file=OUTPUT_DIR+\"train.log\"):\n","    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=log_file)\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","    \n","LOGGER = init_logger()\n","\n","def get_score(more_toxic_preds, less_toxic_preds):\n","    score = np.mean(more_toxic_preds > less_toxic_preds)\n","    return score\n","\n","\n","\n","def get_result(df):\n","    more_toxic_preds = df[\"more_toxic_preds\"].values\n","    less_toxic_preds = df[\"less_toxic_preds\"].values\n","    score = get_score(more_toxic_preds, less_toxic_preds)\n","    LOGGER.info(f\"Score: {score:<.4f}\")\n","    return score\n","\n","\n","def read_processed_data():\n","    validation_data = pd.read_csv(INPUT_PATH + \"validation_data.csv\")\n","    test = pd.read_csv(INPUT_PATH + \"comments_to_score.csv\")\n","    sub = pd.read_csv(INPUT_PATH + \"sample_submission.csv\")\n","    train_src = pd.read_csv(\"../input/jigsaw_1st/PseudoLabelDataset.csv\")\n","    val_comment_unq = pd.concat([validation_data['less_toxic'], validation_data['more_toxic']]).unique()\n","    train2017 = train_src[~train_src['comment_text'].isin(val_comment_unq)]\n","    print(train2017.head())\n","    return train2017, validation_data, test, sub\n","\n","\n","def text_cleaning(text):\n","    template = re.compile(r'https?://\\S+|www\\.\\S+') #Removes website links\n","    text = template.sub(r'', text)\n","    template = re.compile(r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\") #Removes e-mail address\n","    text = template.sub(r'.', text)\n","    # text = re.sub(r\"[^a-zA-Z\\d]\", \" \", text) #Remove special Charecters\n","    ipPattern = re.compile('\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}') # Removes IP address\n","    text = ipPattern.sub(r'', text)\n","    text = text.replace('\\n','')\n","    text = text.strip() # remove spaces at the beginning and at the end of string\n","    return text\n","\n","# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n","\n","\n","def prepare_input(text, tokenizer):\n","    if CFG.tail == 0:\n","        inputs = tokenizer.encode_plus(\n","            text, \n","            return_tensors=None, \n","            add_special_tokens=True, \n","            max_length=CFG.max_length,\n","            pad_to_max_length=True,\n","            truncation=True\n","            )\n","        for k, v in inputs.items():\n","            inputs[k] = torch.tensor(v, dtype=torch.long)\n","    else:\n","        inputs = tokenizer.encode_plus(\n","            text,\n","            return_tensors=None, \n","            add_special_tokens=True, \n","            truncation=True\n","            )\n","        for k, v in inputs.items():\n","            v_length = len(v)\n","            if v_length > CFG.max_length:\n","                v = np.hstack([v[:CFG.head], v[-CFG.tail:]])\n","            if k == 'input_ids':\n","                new_v = np.ones(CFG.max_length) * tokenizer.pad_token_id\n","            else:\n","                new_v = np.zeros(CFG.max_length)\n","            new_v[:v_length] = v \n","            inputs[k] = torch.tensor(new_v, dtype=torch.long)\n","    return inputs\n","\n","\n","# https://zenn.dev/hellorusk/articles/7fd588cae5b173\n","# huggingface Tokenizer の tokenize, encode, encode_plus などの違い\n","class TrainDataset(Dataset):\n","    def __init__(self, df, tokenizer, max_length, is_train=True):\n","        self.df = df\n","        self.tokenizer = tokenizer\n","        self.is_train = is_train\n","        self.max_length = max_length\n","        self.text = df[\"text\"].values\n","        \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, idx):   \n","        text = self.text[idx]\n","        inputs = prepare_input(str(text), self.tokenizer)\n","        ids = inputs[\"input_ids\"]\n","        mask = inputs[\"attention_mask\"]\n","        if self.is_train:\n","            label = self.df[CFG.target_col].values[idx]\n","            return {\n","                'ids': torch.tensor(ids, dtype=torch.long),\n","                'mask': torch.tensor(mask, dtype=torch.long),\n","                'label': torch.tensor(label, dtype=torch.float),\n","            }\n","        else:\n","            return {\n","                'ids': torch.tensor(ids, dtype=torch.long),\n","                'mask': torch.tensor(mask, dtype=torch.long),\n","            }\n","\n","# ====================================================\n","# LOSS\n","# ====================================================\n","\n","__CRITERIONS__ = {}\n","\n","def get_criterion():\n","    if hasattr(nn, CFG.loss_name):\n","        return nn.__getattribute__(CFG.loss_name)(**CFG.loss_params)\n","    elif __CRITERIONS__.get(CFG.loss_name) is not None:\n","        return __CRITERIONS__[CFG.loss_name](**CFG.loss_params)\n","    else:\n","        raise NotImplementedError\n","\n","# ====================================================\n","# Train\n","# ====================================================\n","\n","# Custom optimizer\n","__OPTIMIZERS__ = {}\n","\n","\n","def get_optimizer(model: nn.Module):\n","    optimizer_name = CFG.optimizer_name\n","    if __OPTIMIZERS__.get(optimizer_name) is not None:\n","        return __OPTIMIZERS__[optimizer_name](model.parameters(), **CFG.optimizer_params)\n","    else:\n","        return optim.__getattribute__(optimizer_name)(model.parameters(), **CFG.optimizer_params)\n","\n","def get_scheduler(cfg, optimizer, num_train_steps):\n","    if cfg.scheduler=='linear':\n","        scheduler = get_linear_schedule_with_warmup(\n","            optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","        )\n","    elif cfg.scheduler=='cosine':\n","        scheduler = get_cosine_schedule_with_warmup(\n","            optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","        )\n","    return scheduler\n","\n","class Model(nn.Module):\n","    def __init__(self, modelname_or_path):\n","        super(Model, self).__init__()\n","        self.base_model = AutoModel.from_pretrained(modelname_or_path)\n","        self.fc = nn.Linear(CFG.hidden_node, CFG.num_classes)\n","        self.dropout = nn.Dropout(p=0.)\n","        # self.ln = nn.LayerNorm(CFG.hidden_node)\n","        \n","    def feature(self, input_ids, attention_mask):\n","        outputs = self.base_model(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            output_hidden_states=False\n","        )\n","        last_hidden_states = outputs[0]\n","        feature = torch.mean(last_hidden_states, 1)\n","        return feature\n","\n","    def forward(self, input_ids, attention_mask=None):\n","        feature = self.feature(input_ids, attention_mask)\n","        output = self.fc(self.dropout(feature))\n","        return output\n","\n","\n","\n","\n","def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler,device):\n","    if CFG.use_amp:\n","        scaler = GradScaler()\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","    scores = AverageMeter()\n","    # switch to train mode\n","    model.train()\n","    start = end = time.time()\n","    for step, batch_data in enumerate(train_loader):\n","        # measure data loading time\n","        data_time.update(time.time() - end)\n","        ids = batch_data['ids'].to(device)\n","        mask = batch_data['mask'].to(device)\n","        label = batch_data['label'].to(device)\n","        batch_size = ids.size(0)\n","        if CFG.use_amp:\n","            with autocast():\n","                outputs = model(input_ids=ids, attention_mask=mask)\n","                loss = criterion(torch.squeeze(outputs), label)\n","        else:\n","            outputs = model(input_ids=ids, attention_mask=mask)\n","            loss = criterion(torch.squeeze(outputs), label)\n","        # record loss\n","        losses.update(loss.item(), batch_size)\n","        if CFG.use_amp:\n","            scaler.scale(loss).backward()\n","            scaler.step(optimizer)\n","            scaler.update()\n","        else:\n","            loss.backward()\n","            optimizer.step()\n","        optimizer.zero_grad()\n","        if scheduler is not None:\n","            scheduler.step()\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print(\n","                \"Epoch: [{0}][{1}/{2}] \"\n","                \"Data {data_time.val:.3f} ({data_time.avg:.3f}) \"\n","                \"Elapsed {remain:s} \"\n","                \"Loss: {loss.val:.4f}({loss.avg:.4f}) \"\n","                \"LR: {lr: 8f}\"\n","                .format(\n","                    epoch+1, step, len(train_loader), batch_time=batch_time,\n","                    data_time=data_time, loss=losses,\n","                    remain=timeSince(start, float(step+1)/len(train_loader)),\n","                    lr=scheduler.get_lr()[0]\n","                    )\n","                )\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    # switch to evaluation mode\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, batch_data in enumerate(valid_loader):\n","        # measure data loading time\n","        data_time.update(time.time() - end)\n","        ids = batch_data['ids'].to(device)\n","        mask = batch_data['mask'].to(device)\n","        batch_size = ids.size(0)\n","        # compute loss\n","        with torch.no_grad():\n","            outputs = model(input_ids=ids, attention_mask=mask)\n","        preds.append(outputs.to('cpu').numpy()) \n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print(\n","                \"EVAL: [{0}/{1}] \"\n","                \"Data {data_time.val:.3f} ({data_time.avg:.3f}) \"\n","                \"Elapsed {remain:s} \"\n","                .format(\n","                    step, len(valid_loader), batch_time=batch_time,\n","                    data_time=data_time,\n","                    remain=timeSince(start, float(step+1)/len(valid_loader)),\n","                    )\n","                )\n","    predictions = np.concatenate(preds)\n","    return predictions\n","\n","\n","def train_loop(folds, validation):\n","    validation_last = validation.copy()\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds.reset_index(drop=True)\n","    \n","    print(\"Text cleaning...\")\n","    train_folds['text'] = train_folds['comment_text'].progress_apply(text_cleaning)\n","    validation['less_toxic'] = validation['less_toxic'].progress_apply(text_cleaning)\n","    validation['more_toxic'] = validation['more_toxic'].progress_apply(text_cleaning)\n","    \n","    print(\"Train Shape:\", train_folds.shape)\n","    if CFG.under_sampling:\n","        print(\"Under Sampling\")\n","        train_folds_0 = train_folds[train_folds[\"target\"]==0]\n","        train_folds_0 = train_folds_0.sample(frac=CFG.under_sampling_ratio, random_state=CFG.seed)\n","        train_folds_1 = train_folds[train_folds[\"target\"]>0]\n","        train_folds = pd.concat([train_folds_1, train_folds_0], axis=0).reset_index(drop=True)\n","        print(\"Train Shape (After under sampling):\", train_folds.shape)\n","    \n","    validation_data = sorted(set(validation['less_toxic'].unique()) | set(validation['more_toxic'].unique()))\n","    validation_data = pd.DataFrame({'text': validation_data}).reset_index()\n","    print(\"Valid Shape:\", validation_data.shape)\n","    \n","    tokenizer = AutoTokenizer.from_pretrained(CFG.base_model_name)\n","        \n","    train_dataset = TrainDataset(train_folds, tokenizer, CFG.max_length, is_train=True)\n","    valid_dataset = TrainDataset(validation_data, tokenizer, CFG.max_length, is_train=False)\n","\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=CFG.batch_size, \n","        shuffle=True, \n","        num_workers=CFG.num_workers, \n","        pin_memory=True, \n","        drop_last=True\n","        )\n","    valid_loader = DataLoader(\n","        valid_dataset, \n","        batch_size=CFG.batch_size * 2, \n","        shuffle=False, \n","        num_workers=CFG.num_workers, \n","        pin_memory=True, \n","        drop_last=False\n","        )\n","    \n","\n","    # initialize\n","    model = Model(CFG.base_model_name)\n","    model.to(device)\n","    criterion = get_criterion()\n","\n","    optimizer = get_optimizer(model)\n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    CFG.num_warmup_steps=num_train_steps*CFG.num_warmup_steps_ratio\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","    # scheduler = get_scheduler(optimizer)\n","    best_score = 0\n","    best_loss = np.inf\n","\n","    for epoch in range(CFG.start_epoch, CFG.start_epoch + CFG.epochs):\n","        start_time = time.time()\n","        # train\n","        avg_loss = train_fn(\n","            train_loader, \n","            model, \n","            criterion,\n","            optimizer, \n","            epoch, \n","            scheduler,\n","            device,\n","            )\n","        \n","\n","        # eval\n","        preds = valid_fn(\n","            valid_loader,\n","            model,\n","            criterion, \n","            device\n","            )\n","\n","        # scoring\n","        validation_data[\"pred\"] = preds\n","\n","        if 'less_toxic_preds' in validation.columns:\n","            validation = validation.drop(columns='less_toxic_preds')\n","        if 'more_toxic_preds' in validation.columns:\n","            validation = validation.drop(columns='more_toxic_preds')\n","\n","        rename_cols = {\"text\": 'less_toxic', 'pred': 'less_toxic_preds'}\n","        validation = validation.merge(\n","            validation_data[[\"text\", 'pred']].rename(columns=rename_cols), \n","            on='less_toxic', \n","            how='left'\n","            )\n","        rename_cols = {\"text\": 'more_toxic', 'pred': 'more_toxic_preds'}\n","        validation = validation.merge(\n","            validation_data[[\"text\", 'pred']].rename(columns=rename_cols), \n","            on='more_toxic', \n","            how='left'\n","            )\n","\n","        # scoring\n","        score = get_result(validation)\n","\n","        elapsed = time.time() - start_time\n","        LOGGER.info(f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  time: {elapsed:.0f}s\")\n","        LOGGER.info(f\"Epoch {epoch+1} - Score: {score:.4f}\")\n","\n","        if score > best_score:\n","            best_score = score\n","            LOGGER.info(f\"Epoch {epoch+1} - Save : {score:.4f} Model\")\n","            torch.save({\"model\": model.state_dict()},\n","                        OUTPUT_DIR+'multilingual-toxic-xlm-roberta_best_score.pth')\n","            validation_last[\"more_toxic_preds\"] = validation[\"more_toxic_preds\"]\n","            validation_last[\"less_toxic_preds\"] = validation[\"less_toxic_preds\"]\n","            validation_less = validation_last.drop(\"more_toxic_preds\", axis=1)\n","            validation_more = validation_last.drop(\"less_toxic_preds\", axis=1)\n","    return validation_last, validation_less, validation_more\n","\n","\n","def main():\n","    seed_torch(seed=CFG.seed)\n","    train, validation_data, test, sub = read_processed_data()\n","    if CFG.debug:\n","        CFG.epochs = 1\n","        train = train.sample(n=1000, random_state=CFG.seed).reset_index(drop=True)\n","    oof_df = validation_data.copy()\n","    if CFG.train:\n","        # train \n","        oof_more_toxic = np.zeros(len(validation_data))\n","        oof_less_toxic = np.zeros(len(validation_data))\n","        _oof_df, validation_less, validation_more = train_loop(train, validation_data)\n","        oof_more_toxic += (_oof_df[\"more_toxic_preds\"].values)\n","        oof_less_toxic += (_oof_df[\"less_toxic_preds\"].values)\n","        get_result(_oof_df)\n","        # CV result\n","        LOGGER.info(f\"========== CV ==========\")\n","        oof_df[\"more_toxic_preds\"] = oof_more_toxic\n","        oof_df[\"less_toxic_preds\"] = oof_less_toxic\n","        get_result(oof_df)\n","        # save result\n","        validation_less.to_csv(OUTPUT_DIR+\"less_df.csv\", index=False)\n","        validation_more.to_csv(OUTPUT_DIR+\"more_df.csv\", index=False)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d57ebd7dd85a47a5912e1905ea0e8309","b528ebf7c1694f58a969a7bb2e423542","5ce0af4b1fdd4ab6846ec6a2b056ae77","427cb267433249b5926f61d23ac9fab3","bfed0914291341549ed16c0f07155bc3","b988400c629c410a84b21acc999c2f27","baf1587111ac48ba9a4fff7bc5e2ee71","57fbe7495a604eab8d14887446bead31","e918f3bed5934e9dbf924606a05431bd","747cb88c7edf445fb75a6b683d14e54f","0e840565c549434bbc19259d70a9d339","400a2aa3b926438988a6bd5e48f5d811","344b1c6915714af998a3af9656c652b0","fd1776a2e9cd462d950af6270fd5592a","d962b9f2248c4535b9c7c1f23689caae","927a690261c2471785c475f877326250","ee8f2d29b3af432182abd04e6bb3a680","94ffc84e42e74b81a37e49d8cb77c90d","b5fb2ecc894646f182e35d9d2f0cc3fc","323acabc84b544ed9b1b1ba733e56c99","cdba4ca5091b49f1a928ffd6cc3c0f11","e2d79d58f252479fa5b94c449b74a60c","f1f0d5dd0c174f0ba902c4c2ef9c5741","4884c8ce4d024d1ea716c6a06c93ab5f","531c47b689054cae84a4152fcf5d88ce","761725aa7b6440d38850ad551b57fe04","301140a846154caeadaf91e3999f91ef","972c6dad63c54546948cf9b5a0529204","cae5dd1101f54a3782f14692f3074f8d","d5ec30e3e4964d2a920b1205bf80a66d","497e8df8e99741eb81af146ff08f2d23","62d1917683db4631aa9bc0cca3133fcf","b7d904dccbc44a3c83fd6a039bb5cde3"]},"executionInfo":{"elapsed":13438705,"status":"ok","timestamp":1644206109507,"user":{"displayName":"棚橋直哉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07887718494945196844"},"user_tz":-540},"id":"rzR_ulgEWqWk","outputId":"5dd2ef6c-757c-4ea1-9c6f-b7ee24ab8c0b"},"outputs":[{"name":"stdout","output_type":"stream","text":["                 id  ... pseudo_label\n","0  0000997932d777bf  ...    -0.493725\n","1  000103f0d9cfb60f  ...    -0.636400\n","2  000113f07ec002fd  ...    -0.496514\n","3  0001b41b1c6bb37e  ...    -0.254959\n","4  0001d958c54c6e35  ...    -0.461024\n","\n","[5 rows x 9 columns]\n","Text cleaning...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d57ebd7dd85a47a5912e1905ea0e8309","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/215920 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"400a2aa3b926438988a6bd5e48f5d811","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/30108 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f1f0d5dd0c174f0ba902c4c2ef9c5741","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/30108 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Train Shape: (215920, 10)\n","Valid Shape: (14237, 2)\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at unitary/multilingual-toxic-xlm-roberta were not used when initializing XLMRobertaModel: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n","- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMRobertaModel were not initialized from the model checkpoint at unitary/multilingual-toxic-xlm-roberta and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/3373] Data 0.701 (0.701) Elapsed 0m 1s (remain 81m 57s) Loss: 0.1445(0.1445) LR:  0.000000\n","Epoch: [1][100/3373] Data 0.000 (0.007) Elapsed 1m 19s (remain 42m 44s) Loss: 0.1054(0.1248) LR:  0.000001\n","Epoch: [1][200/3373] Data 0.000 (0.004) Elapsed 2m 36s (remain 41m 16s) Loss: 0.0421(0.0946) LR:  0.000001\n","Epoch: [1][300/3373] Data 0.000 (0.003) Elapsed 3m 54s (remain 39m 55s) Loss: 0.0259(0.0726) LR:  0.000002\n","Epoch: [1][400/3373] Data 0.000 (0.002) Elapsed 5m 12s (remain 38m 36s) Loss: 0.0082(0.0582) LR:  0.000002\n","Epoch: [1][500/3373] Data 0.000 (0.002) Elapsed 6m 30s (remain 37m 17s) Loss: 0.0069(0.0485) LR:  0.000003\n","Epoch: [1][600/3373] Data 0.000 (0.001) Elapsed 7m 48s (remain 35m 59s) Loss: 0.0125(0.0416) LR:  0.000004\n","Epoch: [1][700/3373] Data 0.000 (0.001) Elapsed 9m 5s (remain 34m 40s) Loss: 0.0044(0.0364) LR:  0.000004\n","Epoch: [1][800/3373] Data 0.000 (0.001) Elapsed 10m 23s (remain 33m 22s) Loss: 0.0033(0.0325) LR:  0.000005\n","Epoch: [1][900/3373] Data 0.000 (0.001) Elapsed 11m 41s (remain 32m 4s) Loss: 0.0054(0.0294) LR:  0.000005\n","Epoch: [1][1000/3373] Data 0.000 (0.001) Elapsed 12m 59s (remain 30m 46s) Loss: 0.0060(0.0268) LR:  0.000006\n","Epoch: [1][1100/3373] Data 0.000 (0.001) Elapsed 14m 17s (remain 29m 28s) Loss: 0.0028(0.0247) LR:  0.000007\n","Epoch: [1][1200/3373] Data 0.000 (0.001) Elapsed 15m 34s (remain 28m 10s) Loss: 0.0026(0.0229) LR:  0.000007\n","Epoch: [1][1300/3373] Data 0.000 (0.001) Elapsed 16m 52s (remain 26m 52s) Loss: 0.0033(0.0214) LR:  0.000008\n","Epoch: [1][1400/3373] Data 0.000 (0.001) Elapsed 18m 10s (remain 25m 34s) Loss: 0.0025(0.0201) LR:  0.000008\n","Epoch: [1][1500/3373] Data 0.000 (0.001) Elapsed 19m 28s (remain 24m 16s) Loss: 0.0026(0.0190) LR:  0.000009\n","Epoch: [1][1600/3373] Data 0.000 (0.001) Elapsed 20m 46s (remain 22m 59s) Loss: 0.0021(0.0180) LR:  0.000009\n","Epoch: [1][1700/3373] Data 0.000 (0.001) Elapsed 22m 3s (remain 21m 41s) Loss: 0.0031(0.0171) LR:  0.000010\n","Epoch: [1][1800/3373] Data 0.000 (0.001) Elapsed 23m 21s (remain 20m 23s) Loss: 0.0015(0.0163) LR:  0.000010\n","Epoch: [1][1900/3373] Data 0.000 (0.001) Elapsed 24m 39s (remain 19m 5s) Loss: 0.0018(0.0156) LR:  0.000010\n","Epoch: [1][2000/3373] Data 0.000 (0.001) Elapsed 25m 57s (remain 17m 47s) Loss: 0.0020(0.0149) LR:  0.000010\n","Epoch: [1][2100/3373] Data 0.000 (0.001) Elapsed 27m 15s (remain 16m 29s) Loss: 0.0028(0.0143) LR:  0.000010\n","Epoch: [1][2200/3373] Data 0.000 (0.001) Elapsed 28m 32s (remain 15m 12s) Loss: 0.0018(0.0138) LR:  0.000010\n","Epoch: [1][2300/3373] Data 0.000 (0.001) Elapsed 29m 50s (remain 13m 54s) Loss: 0.0017(0.0133) LR:  0.000010\n","Epoch: [1][2400/3373] Data 0.000 (0.000) Elapsed 31m 8s (remain 12m 36s) Loss: 0.0013(0.0129) LR:  0.000010\n","Epoch: [1][2500/3373] Data 0.000 (0.000) Elapsed 32m 26s (remain 11m 18s) Loss: 0.0018(0.0124) LR:  0.000010\n","Epoch: [1][2600/3373] Data 0.000 (0.000) Elapsed 33m 44s (remain 10m 0s) Loss: 0.0012(0.0121) LR:  0.000010\n","Epoch: [1][2700/3373] Data 0.000 (0.000) Elapsed 35m 1s (remain 8m 42s) Loss: 0.0035(0.0117) LR:  0.000010\n","Epoch: [1][2800/3373] Data 0.000 (0.000) Elapsed 36m 19s (remain 7m 25s) Loss: 0.0024(0.0114) LR:  0.000010\n","Epoch: [1][2900/3373] Data 0.000 (0.000) Elapsed 37m 37s (remain 6m 7s) Loss: 0.0021(0.0111) LR:  0.000010\n","Epoch: [1][3000/3373] Data 0.000 (0.000) Elapsed 38m 55s (remain 4m 49s) Loss: 0.0026(0.0108) LR:  0.000010\n","Epoch: [1][3100/3373] Data 0.000 (0.000) Elapsed 40m 13s (remain 3m 31s) Loss: 0.0026(0.0105) LR:  0.000010\n","Epoch: [1][3200/3373] Data 0.000 (0.000) Elapsed 41m 30s (remain 2m 13s) Loss: 0.0024(0.0102) LR:  0.000010\n","Epoch: [1][3300/3373] Data 0.000 (0.000) Elapsed 42m 48s (remain 0m 56s) Loss: 0.0016(0.0100) LR:  0.000010\n","Epoch: [1][3372/3373] Data 0.000 (0.000) Elapsed 43m 44s (remain 0m 0s) Loss: 0.0012(0.0098) LR:  0.000010\n","EVAL: [0/112] Data 0.883 (0.883) Elapsed 0m 1s (remain 2m 29s) \n","EVAL: [100/112] Data 0.000 (0.009) Elapsed 0m 47s (remain 0m 5s) \n","EVAL: [111/112] Data 0.000 (0.008) Elapsed 0m 52s (remain 0m 0s) \n"]},{"name":"stderr","output_type":"stream","text":["Score: 0.7180\n","Epoch 1 - avg_train_loss: 0.0098  time: 2677s\n","Epoch 1 - Score: 0.7180\n","Epoch 1 - Save : 0.7180 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [2][0/3373] Data 0.602 (0.602) Elapsed 0m 1s (remain 78m 46s) Loss: 0.0014(0.0014) LR:  0.000010\n","Epoch: [2][100/3373] Data 0.000 (0.006) Elapsed 1m 19s (remain 42m 46s) Loss: 0.0013(0.0024) LR:  0.000010\n","Epoch: [2][200/3373] Data 0.000 (0.003) Elapsed 2m 37s (remain 41m 17s) Loss: 0.0014(0.0022) LR:  0.000010\n","Epoch: [2][300/3373] Data 0.000 (0.002) Elapsed 3m 54s (remain 39m 56s) Loss: 0.0027(0.0022) LR:  0.000010\n","Epoch: [2][400/3373] Data 0.000 (0.002) Elapsed 5m 12s (remain 38m 37s) Loss: 0.0021(0.0022) LR:  0.000010\n","Epoch: [2][500/3373] Data 0.000 (0.001) Elapsed 6m 30s (remain 37m 18s) Loss: 0.0009(0.0022) LR:  0.000009\n","Epoch: [2][600/3373] Data 0.000 (0.001) Elapsed 7m 48s (remain 35m 59s) Loss: 0.0018(0.0022) LR:  0.000009\n","Epoch: [2][700/3373] Data 0.000 (0.001) Elapsed 9m 6s (remain 34m 41s) Loss: 0.0030(0.0022) LR:  0.000009\n","Epoch: [2][800/3373] Data 0.000 (0.001) Elapsed 10m 23s (remain 33m 23s) Loss: 0.0012(0.0022) LR:  0.000009\n","Epoch: [2][900/3373] Data 0.000 (0.001) Elapsed 11m 41s (remain 32m 5s) Loss: 0.0022(0.0022) LR:  0.000009\n","Epoch: [2][1000/3373] Data 0.000 (0.001) Elapsed 12m 59s (remain 30m 47s) Loss: 0.0017(0.0022) LR:  0.000009\n","Epoch: [2][1100/3373] Data 0.000 (0.001) Elapsed 14m 17s (remain 29m 29s) Loss: 0.0017(0.0021) LR:  0.000009\n","Epoch: [2][1200/3373] Data 0.000 (0.001) Elapsed 15m 35s (remain 28m 11s) Loss: 0.0021(0.0021) LR:  0.000009\n","Epoch: [2][1300/3373] Data 0.000 (0.001) Elapsed 16m 52s (remain 26m 53s) Loss: 0.0017(0.0021) LR:  0.000009\n","Epoch: [2][1400/3373] Data 0.000 (0.001) Elapsed 18m 10s (remain 25m 35s) Loss: 0.0014(0.0021) LR:  0.000009\n","Epoch: [2][1500/3373] Data 0.000 (0.001) Elapsed 19m 28s (remain 24m 17s) Loss: 0.0011(0.0021) LR:  0.000009\n","Epoch: [2][1600/3373] Data 0.000 (0.001) Elapsed 20m 46s (remain 22m 59s) Loss: 0.0051(0.0021) LR:  0.000009\n","Epoch: [2][1700/3373] Data 0.000 (0.001) Elapsed 22m 4s (remain 21m 41s) Loss: 0.0012(0.0021) LR:  0.000009\n","Epoch: [2][1800/3373] Data 0.000 (0.001) Elapsed 23m 22s (remain 20m 23s) Loss: 0.0049(0.0021) LR:  0.000009\n","Epoch: [2][1900/3373] Data 0.000 (0.001) Elapsed 24m 39s (remain 19m 5s) Loss: 0.0017(0.0021) LR:  0.000009\n","Epoch: [2][2000/3373] Data 0.000 (0.000) Elapsed 25m 57s (remain 17m 48s) Loss: 0.0019(0.0021) LR:  0.000009\n","Epoch: [2][2100/3373] Data 0.000 (0.000) Elapsed 27m 15s (remain 16m 30s) Loss: 0.0028(0.0021) LR:  0.000009\n","Epoch: [2][2200/3373] Data 0.000 (0.000) Elapsed 28m 33s (remain 15m 12s) Loss: 0.0013(0.0021) LR:  0.000008\n","Epoch: [2][2300/3373] Data 0.000 (0.000) Elapsed 29m 51s (remain 13m 54s) Loss: 0.0025(0.0021) LR:  0.000008\n","Epoch: [2][2400/3373] Data 0.000 (0.000) Elapsed 31m 9s (remain 12m 36s) Loss: 0.0014(0.0021) LR:  0.000008\n","Epoch: [2][2500/3373] Data 0.000 (0.000) Elapsed 32m 27s (remain 11m 18s) Loss: 0.0034(0.0021) LR:  0.000008\n","Epoch: [2][2600/3373] Data 0.000 (0.000) Elapsed 33m 44s (remain 10m 1s) Loss: 0.0025(0.0021) LR:  0.000008\n","Epoch: [2][2700/3373] Data 0.000 (0.000) Elapsed 35m 2s (remain 8m 43s) Loss: 0.0024(0.0021) LR:  0.000008\n","Epoch: [2][2800/3373] Data 0.000 (0.000) Elapsed 36m 20s (remain 7m 25s) Loss: 0.0014(0.0021) LR:  0.000008\n","Epoch: [2][2900/3373] Data 0.000 (0.000) Elapsed 37m 38s (remain 6m 7s) Loss: 0.0013(0.0021) LR:  0.000008\n","Epoch: [2][3000/3373] Data 0.000 (0.000) Elapsed 38m 56s (remain 4m 49s) Loss: 0.0012(0.0021) LR:  0.000008\n","Epoch: [2][3100/3373] Data 0.000 (0.000) Elapsed 40m 14s (remain 3m 31s) Loss: 0.0012(0.0021) LR:  0.000008\n","Epoch: [2][3200/3373] Data 0.000 (0.000) Elapsed 41m 32s (remain 2m 13s) Loss: 0.0012(0.0021) LR:  0.000008\n","Epoch: [2][3300/3373] Data 0.000 (0.000) Elapsed 42m 49s (remain 0m 56s) Loss: 0.0014(0.0021) LR:  0.000008\n","Epoch: [2][3372/3373] Data 0.000 (0.000) Elapsed 43m 45s (remain 0m 0s) Loss: 0.0016(0.0021) LR:  0.000008\n","EVAL: [0/112] Data 0.906 (0.906) Elapsed 0m 1s (remain 2m 31s) \n","EVAL: [100/112] Data 0.000 (0.009) Elapsed 0m 47s (remain 0m 5s) \n","EVAL: [111/112] Data 0.000 (0.008) Elapsed 0m 52s (remain 0m 0s) \n"]},{"name":"stderr","output_type":"stream","text":["Score: 0.7207\n","Epoch 2 - avg_train_loss: 0.0021  time: 2679s\n","Epoch 2 - Score: 0.7207\n","Epoch 2 - Save : 0.7207 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [3][0/3373] Data 0.649 (0.649) Elapsed 0m 1s (remain 80m 32s) Loss: 0.0011(0.0011) LR:  0.000008\n","Epoch: [3][100/3373] Data 0.000 (0.007) Elapsed 1m 19s (remain 42m 48s) Loss: 0.0017(0.0017) LR:  0.000007\n","Epoch: [3][200/3373] Data 0.000 (0.003) Elapsed 2m 37s (remain 41m 19s) Loss: 0.0013(0.0017) LR:  0.000007\n","Epoch: [3][300/3373] Data 0.000 (0.002) Elapsed 3m 54s (remain 39m 58s) Loss: 0.0015(0.0017) LR:  0.000007\n","Epoch: [3][400/3373] Data 0.000 (0.002) Elapsed 5m 12s (remain 38m 38s) Loss: 0.0022(0.0017) LR:  0.000007\n","Epoch: [3][500/3373] Data 0.000 (0.001) Elapsed 6m 30s (remain 37m 19s) Loss: 0.0010(0.0017) LR:  0.000007\n","Epoch: [3][600/3373] Data 0.000 (0.001) Elapsed 7m 48s (remain 36m 0s) Loss: 0.0017(0.0017) LR:  0.000007\n","Epoch: [3][700/3373] Data 0.000 (0.001) Elapsed 9m 6s (remain 34m 42s) Loss: 0.0016(0.0018) LR:  0.000007\n","Epoch: [3][800/3373] Data 0.000 (0.001) Elapsed 10m 24s (remain 33m 24s) Loss: 0.0013(0.0018) LR:  0.000007\n","Epoch: [3][900/3373] Data 0.000 (0.001) Elapsed 11m 42s (remain 32m 6s) Loss: 0.0012(0.0018) LR:  0.000007\n","Epoch: [3][1000/3373] Data 0.000 (0.001) Elapsed 12m 59s (remain 30m 48s) Loss: 0.0014(0.0018) LR:  0.000007\n","Epoch: [3][1100/3373] Data 0.000 (0.001) Elapsed 14m 17s (remain 29m 29s) Loss: 0.0035(0.0018) LR:  0.000006\n","Epoch: [3][1200/3373] Data 0.000 (0.001) Elapsed 15m 35s (remain 28m 11s) Loss: 0.0015(0.0018) LR:  0.000006\n","Epoch: [3][1300/3373] Data 0.000 (0.001) Elapsed 16m 53s (remain 26m 53s) Loss: 0.0009(0.0018) LR:  0.000006\n","Epoch: [3][1400/3373] Data 0.000 (0.001) Elapsed 18m 11s (remain 25m 35s) Loss: 0.0015(0.0018) LR:  0.000006\n","Epoch: [3][1500/3373] Data 0.000 (0.001) Elapsed 19m 29s (remain 24m 18s) Loss: 0.0018(0.0018) LR:  0.000006\n","Epoch: [3][1600/3373] Data 0.000 (0.001) Elapsed 20m 46s (remain 23m 0s) Loss: 0.0016(0.0017) LR:  0.000006\n","Epoch: [3][1700/3373] Data 0.000 (0.001) Elapsed 22m 4s (remain 21m 42s) Loss: 0.0011(0.0018) LR:  0.000006\n","Epoch: [3][1800/3373] Data 0.000 (0.001) Elapsed 23m 22s (remain 20m 24s) Loss: 0.0017(0.0017) LR:  0.000006\n","Epoch: [3][1900/3373] Data 0.000 (0.001) Elapsed 24m 40s (remain 19m 6s) Loss: 0.0017(0.0017) LR:  0.000006\n","Epoch: [3][2000/3373] Data 0.000 (0.001) Elapsed 25m 58s (remain 17m 48s) Loss: 0.0026(0.0017) LR:  0.000006\n","Epoch: [3][2100/3373] Data 0.000 (0.001) Elapsed 27m 16s (remain 16m 30s) Loss: 0.0020(0.0017) LR:  0.000005\n","Epoch: [3][2200/3373] Data 0.000 (0.000) Elapsed 28m 34s (remain 15m 12s) Loss: 0.0026(0.0017) LR:  0.000005\n","Epoch: [3][2300/3373] Data 0.000 (0.000) Elapsed 29m 51s (remain 13m 54s) Loss: 0.0014(0.0017) LR:  0.000005\n","Epoch: [3][2400/3373] Data 0.000 (0.000) Elapsed 31m 9s (remain 12m 36s) Loss: 0.0039(0.0017) LR:  0.000005\n","Epoch: [3][2500/3373] Data 0.000 (0.000) Elapsed 32m 27s (remain 11m 19s) Loss: 0.0015(0.0017) LR:  0.000005\n","Epoch: [3][2600/3373] Data 0.000 (0.000) Elapsed 33m 45s (remain 10m 1s) Loss: 0.0016(0.0017) LR:  0.000005\n","Epoch: [3][2700/3373] Data 0.000 (0.000) Elapsed 35m 3s (remain 8m 43s) Loss: 0.0018(0.0017) LR:  0.000005\n","Epoch: [3][2800/3373] Data 0.000 (0.000) Elapsed 36m 21s (remain 7m 25s) Loss: 0.0010(0.0017) LR:  0.000005\n","Epoch: [3][2900/3373] Data 0.000 (0.000) Elapsed 37m 39s (remain 6m 7s) Loss: 0.0033(0.0017) LR:  0.000005\n","Epoch: [3][3000/3373] Data 0.000 (0.000) Elapsed 38m 57s (remain 4m 49s) Loss: 0.0011(0.0017) LR:  0.000005\n","Epoch: [3][3100/3373] Data 0.000 (0.000) Elapsed 40m 14s (remain 3m 31s) Loss: 0.0015(0.0017) LR:  0.000004\n","Epoch: [3][3200/3373] Data 0.000 (0.000) Elapsed 41m 32s (remain 2m 13s) Loss: 0.0010(0.0017) LR:  0.000004\n","Epoch: [3][3300/3373] Data 0.000 (0.000) Elapsed 42m 50s (remain 0m 56s) Loss: 0.0013(0.0017) LR:  0.000004\n","Epoch: [3][3372/3373] Data 0.000 (0.000) Elapsed 43m 46s (remain 0m 0s) Loss: 0.0009(0.0017) LR:  0.000004\n","EVAL: [0/112] Data 0.858 (0.858) Elapsed 0m 1s (remain 2m 26s) \n","EVAL: [100/112] Data 0.000 (0.009) Elapsed 0m 47s (remain 0m 5s) \n","EVAL: [111/112] Data 0.000 (0.008) Elapsed 0m 52s (remain 0m 0s) \n"]},{"name":"stderr","output_type":"stream","text":["Score: 0.7223\n","Epoch 3 - avg_train_loss: 0.0017  time: 2679s\n","Epoch 3 - Score: 0.7223\n","Epoch 3 - Save : 0.7223 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [4][0/3373] Data 0.682 (0.682) Elapsed 0m 1s (remain 83m 3s) Loss: 0.0012(0.0012) LR:  0.000004\n","Epoch: [4][100/3373] Data 0.000 (0.007) Elapsed 1m 19s (remain 42m 50s) Loss: 0.0009(0.0015) LR:  0.000004\n","Epoch: [4][200/3373] Data 0.000 (0.004) Elapsed 2m 37s (remain 41m 20s) Loss: 0.0011(0.0016) LR:  0.000004\n","Epoch: [4][300/3373] Data 0.000 (0.002) Elapsed 3m 55s (remain 39m 58s) Loss: 0.0008(0.0016) LR:  0.000004\n","Epoch: [4][400/3373] Data 0.000 (0.002) Elapsed 5m 12s (remain 38m 39s) Loss: 0.0012(0.0016) LR:  0.000004\n","Epoch: [4][500/3373] Data 0.000 (0.002) Elapsed 6m 30s (remain 37m 19s) Loss: 0.0007(0.0015) LR:  0.000004\n","Epoch: [4][600/3373] Data 0.000 (0.001) Elapsed 7m 48s (remain 36m 1s) Loss: 0.0010(0.0015) LR:  0.000004\n","Epoch: [4][700/3373] Data 0.000 (0.001) Elapsed 9m 6s (remain 34m 42s) Loss: 0.0009(0.0015) LR:  0.000003\n","Epoch: [4][800/3373] Data 0.000 (0.001) Elapsed 10m 24s (remain 33m 24s) Loss: 0.0041(0.0015) LR:  0.000003\n","Epoch: [4][900/3373] Data 0.000 (0.001) Elapsed 11m 42s (remain 32m 6s) Loss: 0.0009(0.0015) LR:  0.000003\n","Epoch: [4][1000/3373] Data 0.000 (0.001) Elapsed 12m 59s (remain 30m 48s) Loss: 0.0014(0.0015) LR:  0.000003\n","Epoch: [4][1100/3373] Data 0.000 (0.001) Elapsed 14m 17s (remain 29m 30s) Loss: 0.0012(0.0015) LR:  0.000003\n","Epoch: [4][1200/3373] Data 0.000 (0.001) Elapsed 15m 35s (remain 28m 12s) Loss: 0.0019(0.0015) LR:  0.000003\n","Epoch: [4][1300/3373] Data 0.000 (0.001) Elapsed 16m 53s (remain 26m 54s) Loss: 0.0016(0.0015) LR:  0.000003\n","Epoch: [4][1400/3373] Data 0.000 (0.001) Elapsed 18m 11s (remain 25m 36s) Loss: 0.0010(0.0015) LR:  0.000003\n","Epoch: [4][1500/3373] Data 0.000 (0.001) Elapsed 19m 29s (remain 24m 18s) Loss: 0.0012(0.0015) LR:  0.000003\n","Epoch: [4][1600/3373] Data 0.000 (0.001) Elapsed 20m 47s (remain 23m 0s) Loss: 0.0013(0.0015) LR:  0.000003\n","Epoch: [4][1700/3373] Data 0.000 (0.001) Elapsed 22m 4s (remain 21m 42s) Loss: 0.0036(0.0015) LR:  0.000002\n","Epoch: [4][1800/3373] Data 0.000 (0.001) Elapsed 23m 22s (remain 20m 24s) Loss: 0.0011(0.0015) LR:  0.000002\n","Epoch: [4][1900/3373] Data 0.000 (0.001) Elapsed 24m 40s (remain 19m 6s) Loss: 0.0013(0.0015) LR:  0.000002\n","Epoch: [4][2000/3373] Data 0.000 (0.001) Elapsed 25m 58s (remain 17m 48s) Loss: 0.0009(0.0015) LR:  0.000002\n","Epoch: [4][2100/3373] Data 0.000 (0.001) Elapsed 27m 16s (remain 16m 30s) Loss: 0.0019(0.0015) LR:  0.000002\n","Epoch: [4][2200/3373] Data 0.000 (0.001) Elapsed 28m 34s (remain 15m 12s) Loss: 0.0010(0.0015) LR:  0.000002\n","Epoch: [4][2300/3373] Data 0.000 (0.000) Elapsed 29m 52s (remain 13m 54s) Loss: 0.0013(0.0015) LR:  0.000002\n","Epoch: [4][2400/3373] Data 0.000 (0.000) Elapsed 31m 9s (remain 12m 37s) Loss: 0.0008(0.0015) LR:  0.000002\n","Epoch: [4][2500/3373] Data 0.000 (0.000) Elapsed 32m 27s (remain 11m 19s) Loss: 0.0011(0.0015) LR:  0.000002\n","Epoch: [4][2600/3373] Data 0.000 (0.000) Elapsed 33m 45s (remain 10m 1s) Loss: 0.0015(0.0015) LR:  0.000002\n","Epoch: [4][2700/3373] Data 0.000 (0.000) Elapsed 35m 3s (remain 8m 43s) Loss: 0.0026(0.0015) LR:  0.000002\n","Epoch: [4][2800/3373] Data 0.000 (0.000) Elapsed 36m 21s (remain 7m 25s) Loss: 0.0024(0.0015) LR:  0.000002\n","Epoch: [4][2900/3373] Data 0.000 (0.000) Elapsed 37m 39s (remain 6m 7s) Loss: 0.0007(0.0015) LR:  0.000002\n","Epoch: [4][3000/3373] Data 0.000 (0.000) Elapsed 38m 57s (remain 4m 49s) Loss: 0.0012(0.0015) LR:  0.000001\n","Epoch: [4][3100/3373] Data 0.000 (0.000) Elapsed 40m 14s (remain 3m 31s) Loss: 0.0014(0.0015) LR:  0.000001\n","Epoch: [4][3200/3373] Data 0.000 (0.000) Elapsed 41m 32s (remain 2m 13s) Loss: 0.0019(0.0015) LR:  0.000001\n","Epoch: [4][3300/3373] Data 0.000 (0.000) Elapsed 42m 50s (remain 0m 56s) Loss: 0.0010(0.0015) LR:  0.000001\n","Epoch: [4][3372/3373] Data 0.000 (0.000) Elapsed 43m 46s (remain 0m 0s) Loss: 0.0008(0.0015) LR:  0.000001\n","EVAL: [0/112] Data 0.888 (0.888) Elapsed 0m 1s (remain 2m 29s) \n","EVAL: [100/112] Data 0.000 (0.009) Elapsed 0m 47s (remain 0m 5s) \n","EVAL: [111/112] Data 0.000 (0.008) Elapsed 0m 52s (remain 0m 0s) \n"]},{"name":"stderr","output_type":"stream","text":["Score: 0.7233\n","Epoch 4 - avg_train_loss: 0.0015  time: 2679s\n","Epoch 4 - Score: 0.7233\n","Epoch 4 - Save : 0.7233 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [5][0/3373] Data 0.692 (0.692) Elapsed 0m 1s (remain 83m 22s) Loss: 0.0007(0.0007) LR:  0.000001\n","Epoch: [5][100/3373] Data 0.000 (0.007) Elapsed 1m 19s (remain 42m 50s) Loss: 0.0020(0.0013) LR:  0.000001\n","Epoch: [5][200/3373] Data 0.000 (0.004) Elapsed 2m 37s (remain 41m 20s) Loss: 0.0008(0.0013) LR:  0.000001\n","Epoch: [5][300/3373] Data 0.000 (0.003) Elapsed 3m 55s (remain 39m 58s) Loss: 0.0016(0.0013) LR:  0.000001\n","Epoch: [5][400/3373] Data 0.000 (0.002) Elapsed 5m 12s (remain 38m 38s) Loss: 0.0007(0.0013) LR:  0.000001\n","Epoch: [5][500/3373] Data 0.000 (0.002) Elapsed 6m 30s (remain 37m 19s) Loss: 0.0014(0.0013) LR:  0.000001\n","Epoch: [5][600/3373] Data 0.000 (0.001) Elapsed 7m 48s (remain 36m 0s) Loss: 0.0025(0.0014) LR:  0.000001\n","Epoch: [5][700/3373] Data 0.000 (0.001) Elapsed 9m 6s (remain 34m 42s) Loss: 0.0006(0.0013) LR:  0.000001\n","Epoch: [5][800/3373] Data 0.000 (0.001) Elapsed 10m 24s (remain 33m 24s) Loss: 0.0010(0.0014) LR:  0.000001\n","Epoch: [5][900/3373] Data 0.000 (0.001) Elapsed 11m 41s (remain 32m 5s) Loss: 0.0011(0.0014) LR:  0.000001\n","Epoch: [5][1000/3373] Data 0.000 (0.001) Elapsed 12m 59s (remain 30m 47s) Loss: 0.0009(0.0013) LR:  0.000001\n","Epoch: [5][1100/3373] Data 0.000 (0.001) Elapsed 14m 17s (remain 29m 29s) Loss: 0.0010(0.0014) LR:  0.000001\n","Epoch: [5][1200/3373] Data 0.000 (0.001) Elapsed 15m 35s (remain 28m 11s) Loss: 0.0011(0.0013) LR:  0.000000\n","Epoch: [5][1300/3373] Data 0.000 (0.001) Elapsed 16m 53s (remain 26m 53s) Loss: 0.0009(0.0013) LR:  0.000000\n","Epoch: [5][1400/3373] Data 0.000 (0.001) Elapsed 18m 11s (remain 25m 35s) Loss: 0.0015(0.0013) LR:  0.000000\n","Epoch: [5][1500/3373] Data 0.000 (0.001) Elapsed 19m 28s (remain 24m 17s) Loss: 0.0010(0.0013) LR:  0.000000\n","Epoch: [5][1600/3373] Data 0.000 (0.001) Elapsed 20m 46s (remain 22m 59s) Loss: 0.0016(0.0013) LR:  0.000000\n","Epoch: [5][1700/3373] Data 0.000 (0.001) Elapsed 22m 4s (remain 21m 42s) Loss: 0.0020(0.0014) LR:  0.000000\n","Epoch: [5][1800/3373] Data 0.000 (0.001) Elapsed 23m 22s (remain 20m 24s) Loss: 0.0016(0.0013) LR:  0.000000\n","Epoch: [5][1900/3373] Data 0.000 (0.001) Elapsed 24m 40s (remain 19m 6s) Loss: 0.0020(0.0013) LR:  0.000000\n","Epoch: [5][2000/3373] Data 0.000 (0.001) Elapsed 25m 58s (remain 17m 48s) Loss: 0.0012(0.0013) LR:  0.000000\n","Epoch: [5][2100/3373] Data 0.000 (0.001) Elapsed 27m 15s (remain 16m 30s) Loss: 0.0008(0.0013) LR:  0.000000\n","Epoch: [5][2200/3373] Data 0.000 (0.001) Elapsed 28m 33s (remain 15m 12s) Loss: 0.0013(0.0013) LR:  0.000000\n","Epoch: [5][2300/3373] Data 0.000 (0.000) Elapsed 29m 51s (remain 13m 54s) Loss: 0.0014(0.0013) LR:  0.000000\n","Epoch: [5][2400/3373] Data 0.000 (0.000) Elapsed 31m 9s (remain 12m 36s) Loss: 0.0013(0.0013) LR:  0.000000\n","Epoch: [5][2500/3373] Data 0.000 (0.000) Elapsed 32m 27s (remain 11m 18s) Loss: 0.0012(0.0013) LR:  0.000000\n","Epoch: [5][2600/3373] Data 0.000 (0.000) Elapsed 33m 44s (remain 10m 1s) Loss: 0.0010(0.0013) LR:  0.000000\n","Epoch: [5][2700/3373] Data 0.000 (0.000) Elapsed 35m 2s (remain 8m 43s) Loss: 0.0018(0.0014) LR:  0.000000\n","Epoch: [5][2800/3373] Data 0.000 (0.000) Elapsed 36m 20s (remain 7m 25s) Loss: 0.0011(0.0014) LR:  0.000000\n","Epoch: [5][2900/3373] Data 0.000 (0.000) Elapsed 37m 38s (remain 6m 7s) Loss: 0.0007(0.0013) LR:  0.000000\n","Epoch: [5][3000/3373] Data 0.000 (0.000) Elapsed 38m 56s (remain 4m 49s) Loss: 0.0011(0.0014) LR:  0.000000\n","Epoch: [5][3100/3373] Data 0.000 (0.000) Elapsed 40m 14s (remain 3m 31s) Loss: 0.0025(0.0014) LR:  0.000000\n","Epoch: [5][3200/3373] Data 0.000 (0.000) Elapsed 41m 31s (remain 2m 13s) Loss: 0.0010(0.0014) LR:  0.000000\n","Epoch: [5][3300/3373] Data 0.000 (0.000) Elapsed 42m 49s (remain 0m 56s) Loss: 0.0014(0.0014) LR:  0.000000\n","Epoch: [5][3372/3373] Data 0.000 (0.000) Elapsed 43m 45s (remain 0m 0s) Loss: 0.0009(0.0014) LR:  0.000000\n","EVAL: [0/112] Data 0.792 (0.792) Elapsed 0m 1s (remain 2m 19s) \n","EVAL: [100/112] Data 0.000 (0.008) Elapsed 0m 47s (remain 0m 5s) \n","EVAL: [111/112] Data 0.000 (0.007) Elapsed 0m 52s (remain 0m 0s) \n"]},{"name":"stderr","output_type":"stream","text":["Score: 0.7231\n","Epoch 5 - avg_train_loss: 0.0014  time: 2678s\n","Epoch 5 - Score: 0.7231\n","Score: 0.7233\n","========== CV ==========\n","Score: 0.7233\n"]}],"source":["if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CYxwIUoqWquN"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyO8oFbF8ViA6mkzl/ag+Jx4","collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1yJv_KJbYJzk2q4mobfDXMzmDMQVvIl95","name":"exp4002.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"01f6debc355740e6a5ca47c93dc577ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"02eb21a1d640458385822b268f3b5ed5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02fdd5f686834ac4afb37917167664b8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08d5018c177b4756961ffbdeda042316":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cbf77fd80f1e4a479b754f0487565b59","IPY_MODEL_def3aa08969043c9b61f07e2a9e37dfb","IPY_MODEL_ac944fecbf31477786aa6af6a29ce637"],"layout":"IPY_MODEL_8f4fa550afad4bc5827c04bd78f4c055"}},"09660424d318405f9c9bd9b253f420d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e640816150f4299a270528b6e2d1fc4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e840565c549434bbc19259d70a9d339":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10cde17b97054d2dab6608529195f9aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13293764b65e431a83145224316a669a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1425568c0382468bb61f119bc48fb9df":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc06fd1ed9254ed19ffa3ee17ee19a3c","max":30108,"min":0,"orientation":"horizontal","style":"IPY_MODEL_54a4bbf1c5a0492c8cdef33ece0ba62f","value":30108}},"17ae7630db904ab6b8809e861ccaf719":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f09c65e2d6754bccbdf4f81e7a5c73a2","IPY_MODEL_7592e2b5f3f74cb9ab6838e2a43bcef9","IPY_MODEL_f9f36f2bbe2f4cd7a9d9b74ce3309678"],"layout":"IPY_MODEL_710a13db1410425784308168a2511a69"}},"18c8b8810e1944038401af37b514e4ac":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19de70fba8a54a6c85b3f80afe98e7a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_757f1cdc8d5349678c1e25aa740b8b3b","placeholder":"​","style":"IPY_MODEL_905a5d20c26f44eb837a47598035bb75","value":"Downloading: 100%"}},"1e15472bcd974b7fae7fb8229d0dd6c5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"26744ec4a4814490a2b6b25890ec8b01":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9113254db2fe436fbd9a39212348116c","placeholder":"​","style":"IPY_MODEL_97dcb0ca9e8242338e99c5c98c9c6b22","value":"100%"}},"268443e43dfe4794ba4d6148bee647aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b20040e57134ebc8d5b06456a5047fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9dde50526ea4ff0bf3a1eabb545a947","placeholder":"​","style":"IPY_MODEL_d5615f2eb3e74c6aa737ef7222ba6bec","value":" 1.04G/1.04G [00:22&lt;00:00, 61.1MB/s]"}},"2b9c29e216ef44b99f2dc06bb45a2efc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bdf2a8713de54e77bddd86dded9e0830","IPY_MODEL_718873656f7e44d8b84cc80047b93a67","IPY_MODEL_2c1361aae01540428372581496f64a1c"],"layout":"IPY_MODEL_77e586b10fad4db9b12ec2c0304073fa"}},"2c1361aae01540428372581496f64a1c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d41bdb2269cf496284e0210ce1013eb8","placeholder":"​","style":"IPY_MODEL_53cb2b28c6354849ae0314d9cdd537f6","value":" 4.83M/4.83M [00:00&lt;00:00, 5.65MB/s]"}},"2fba76e751d54632947059a42f1a9c04":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_809bc09ffae84281a7503b9f0d3072e1","placeholder":"​","style":"IPY_MODEL_01f6debc355740e6a5ca47c93dc577ec","value":"100%"}},"301140a846154caeadaf91e3999f91ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7d904dccbc44a3c83fd6a039bb5cde3","placeholder":"​","style":"IPY_MODEL_62d1917683db4631aa9bc0cca3133fcf","value":" 30108/30108 [00:01&lt;00:00, 22367.22it/s]"}},"30e6a03031a548d9821ad49ae9adc3ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cdc670a4c9fa406dafa6f7e473026ea3","placeholder":"​","style":"IPY_MODEL_3adb92a7d52441bba2187219ac8b656d","value":" 30108/30108 [00:01&lt;00:00, 24597.12it/s]"}},"323acabc84b544ed9b1b1ba733e56c99":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"344b1c6915714af998a3af9656c652b0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3519635cdae64507832cc2244ff73633":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fb52dd2f2d44dfd9e0dc83d931565eb","max":30108,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b29652f3fb774157b9149f2f2b16e682","value":30108}},"3637eef6e2a44d1798c7fc9cfe531e54":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"36fc58d1030246d387f4963db4b4c1d6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3adb92a7d52441bba2187219ac8b656d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3cb4e65b9c12446abe85c6ce4bf33083":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e3031b3a8db4e9380607bc2feb8c94c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"400a2aa3b926438988a6bd5e48f5d811":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fd1776a2e9cd462d950af6270fd5592a","IPY_MODEL_d962b9f2248c4535b9c7c1f23689caae","IPY_MODEL_927a690261c2471785c475f877326250"],"layout":"IPY_MODEL_344b1c6915714af998a3af9656c652b0"}},"427cb267433249b5926f61d23ac9fab3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e918f3bed5934e9dbf924606a05431bd","max":215920,"min":0,"orientation":"horizontal","style":"IPY_MODEL_57fbe7495a604eab8d14887446bead31","value":215920}},"4884c8ce4d024d1ea716c6a06c93ab5f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"497e8df8e99741eb81af146ff08f2d23":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4abc891d05f345fb9fa32ec646c62f50":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d7978edbd0f407299c23c38daf5c66a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ee2f6c67c534a95a229e9d5113d225e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_02eb21a1d640458385822b268f3b5ed5","placeholder":"​","style":"IPY_MODEL_a2f86fbf2c414306936e66e9db7f1631","value":" 150/150 [00:00&lt;00:00, 6.35kB/s]"}},"508e710fdc824b5abea4670148b1aa07":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"527f52a21797403288bdfd39effc3b37":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"531c47b689054cae84a4152fcf5d88ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cae5dd1101f54a3782f14692f3074f8d","placeholder":"​","style":"IPY_MODEL_972c6dad63c54546948cf9b5a0529204","value":"100%"}},"53cb2b28c6354849ae0314d9cdd537f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"53f91566a2824d8780652ae523750386":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_916eed61cd26427b927486b396bf4082","placeholder":"​","style":"IPY_MODEL_7994964c02f24b85bace1ab09bed6c33","value":" 215920/215920 [00:06&lt;00:00, 32686.66it/s]"}},"54a4bbf1c5a0492c8cdef33ece0ba62f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5575e0208d484de2b9f38c346bf06772":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_527f52a21797403288bdfd39effc3b37","placeholder":"​","style":"IPY_MODEL_62d831cfaad2419492c4dced69f5f8e7","value":"100%"}},"57fbe7495a604eab8d14887446bead31":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"581c1f2fb3d344cf85f2466b06fae04d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"588739ebee354702b3b9cc29fcc3e9fb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58d9ca95e2f4423a9f2644750f2a80aa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59c1bbe003694ca8b8e83d43ab76412d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c0d89c0169f467db1848d5bd35df62a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ce0af4b1fdd4ab6846ec6a2b056ae77":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_baf1587111ac48ba9a4fff7bc5e2ee71","placeholder":"​","style":"IPY_MODEL_b988400c629c410a84b21acc999c2f27","value":"100%"}},"6144854c24bf4a1b8b3ae8a856928a60":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fa1bd1fa8b04cacb4c5661704625379","max":635,"min":0,"orientation":"horizontal","style":"IPY_MODEL_adc1dd7637eb4773afe75940948c1f0a","value":635}},"62039c2f2ba5479bb5193fc9761a3aed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"62a59d3664a2411a9fd1cabec99e8b56":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62d1917683db4631aa9bc0cca3133fcf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62d831cfaad2419492c4dced69f5f8e7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6465b09b5753494aa6e34585cb991e6e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a071947768940028e3a3c2b36cd7510":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7036b45db86546708bddcf6b1b348f1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb9ea8a7ba7342bc83fb5d89d46bfdc7","max":150,"min":0,"orientation":"horizontal","style":"IPY_MODEL_62039c2f2ba5479bb5193fc9761a3aed","value":150}},"710a13db1410425784308168a2511a69":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"718873656f7e44d8b84cc80047b93a67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8a800f6fb644c6e88266bfec348369c","max":5069051,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c51207431f3a40c3ac396245f2f0aeb6","value":5069051}},"7248e778b59a4c5895aa84c47afed4f3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"747cb88c7edf445fb75a6b683d14e54f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"757f1cdc8d5349678c1e25aa740b8b3b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7592e2b5f3f74cb9ab6838e2a43bcef9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e3031b3a8db4e9380607bc2feb8c94c","max":211,"min":0,"orientation":"horizontal","style":"IPY_MODEL_86178b974b8d4725bfa20426ee70c349","value":211}},"761725aa7b6440d38850ad551b57fe04":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_497e8df8e99741eb81af146ff08f2d23","max":30108,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d5ec30e3e4964d2a920b1205bf80a66d","value":30108}},"77b28a6fd8fe49578b4bd1221c2b8ea7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f48474291d94b4c8096c5c9a2286169","placeholder":"​","style":"IPY_MODEL_09660424d318405f9c9bd9b253f420d5","value":"Downloading: 100%"}},"77e586b10fad4db9b12ec2c0304073fa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"787cedc8a9644ca6b27e3b84b3bc611b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c86a9b79ec74329a6622a18bfbe2b1c","placeholder":"​","style":"IPY_MODEL_f2bc9c42aea1494da234a15c2acea1f9","value":" 30108/30108 [00:01&lt;00:00, 29352.46it/s]"}},"795f987811454ee3a2c0224de68b61bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_26744ec4a4814490a2b6b25890ec8b01","IPY_MODEL_7ba070589a7c48199cab9bc88c4ebd80","IPY_MODEL_53f91566a2824d8780652ae523750386"],"layout":"IPY_MODEL_36fc58d1030246d387f4963db4b4c1d6"}},"7994964c02f24b85bace1ab09bed6c33":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a0a76b480e54247a13db55dfe7aa7ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ba070589a7c48199cab9bc88c4ebd80":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_62a59d3664a2411a9fd1cabec99e8b56","max":215920,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f0b4f75f96df461cbf26c9a0bda60e35","value":215920}},"7c4cf013a912469b979028456747bfec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb1d769dfe194dda826f01f36b10379b","placeholder":"​","style":"IPY_MODEL_ad22404aae404cec8928ec67b9bfb50f","value":" 30108/30108 [00:01&lt;00:00, 26495.54it/s]"}},"7c86a9b79ec74329a6622a18bfbe2b1c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f48474291d94b4c8096c5c9a2286169":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fcacdfa272f4c36b0ee369f6024cc16":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"809bc09ffae84281a7503b9f0d3072e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"832de0c0238b4f759ce5ec7a054fe1a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18c8b8810e1944038401af37b514e4ac","placeholder":"​","style":"IPY_MODEL_aa8cf84b385d4161bc0d67461ba2cbd6","value":"100%"}},"8413f086de5c4c13b25a604a0e626cc8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_77b28a6fd8fe49578b4bd1221c2b8ea7","IPY_MODEL_e89dd07958a040fda22e259803749d08","IPY_MODEL_2b20040e57134ebc8d5b06456a5047fc"],"layout":"IPY_MODEL_581c1f2fb3d344cf85f2466b06fae04d"}},"843841274c7440509dc81f5c0c8704ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86178b974b8d4725bfa20426ee70c349":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8f4fa550afad4bc5827c04bd78f4c055":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fa1bd1fa8b04cacb4c5661704625379":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fb52dd2f2d44dfd9e0dc83d931565eb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"900158f040a34893b6fff95e17608335":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a20a9248206a45ec97df1e2989dcf655","IPY_MODEL_6144854c24bf4a1b8b3ae8a856928a60","IPY_MODEL_aac11dd6865f426a8374e8ea7ebbe115"],"layout":"IPY_MODEL_99b44d52d4aa4d45abb182a6a1ed751a"}},"905a5d20c26f44eb837a47598035bb75":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9113254db2fe436fbd9a39212348116c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"916eed61cd26427b927486b396bf4082":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"927a690261c2471785c475f877326250":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2d79d58f252479fa5b94c449b74a60c","placeholder":"​","style":"IPY_MODEL_cdba4ca5091b49f1a928ffd6cc3c0f11","value":" 30108/30108 [00:01&lt;00:00, 24444.80it/s]"}},"947e178b34214e8daf33936d02f234e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_832de0c0238b4f759ce5ec7a054fe1a6","IPY_MODEL_3519635cdae64507832cc2244ff73633","IPY_MODEL_30e6a03031a548d9821ad49ae9adc3ec"],"layout":"IPY_MODEL_508e710fdc824b5abea4670148b1aa07"}},"94ffc84e42e74b81a37e49d8cb77c90d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9684e5747a114f5cbb07c9726e1474b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_96a975967267477e82c9acef191ed7c0","placeholder":"​","style":"IPY_MODEL_7a0a76b480e54247a13db55dfe7aa7ff","value":"100%"}},"96a975967267477e82c9acef191ed7c0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"972c6dad63c54546948cf9b5a0529204":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97dcb0ca9e8242338e99c5c98c9c6b22":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"99b44d52d4aa4d45abb182a6a1ed751a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bc44dac60394abfb492c0650429f17f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e22cab924824846a9c469ef25a7f42e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_13293764b65e431a83145224316a669a","max":30108,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3637eef6e2a44d1798c7fc9cfe531e54","value":30108}},"a20a9248206a45ec97df1e2989dcf655":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4abc891d05f345fb9fa32ec646c62f50","placeholder":"​","style":"IPY_MODEL_e6dba378f6514b889e91d27ed8dfe8c3","value":"Downloading: 100%"}},"a2f86fbf2c414306936e66e9db7f1631":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7b28df5a69c4e9180407b69ce401670":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e640816150f4299a270528b6e2d1fc4","placeholder":"​","style":"IPY_MODEL_843841274c7440509dc81f5c0c8704ab","value":" 30108/30108 [00:01&lt;00:00, 27905.79it/s]"}},"aa3e5e2c3cd04ef88745c1ddb0050f68":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa8cf84b385d4161bc0d67461ba2cbd6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aac11dd6865f426a8374e8ea7ebbe115":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7248e778b59a4c5895aa84c47afed4f3","placeholder":"​","style":"IPY_MODEL_9bc44dac60394abfb492c0650429f17f","value":" 635/635 [00:00&lt;00:00, 27.8kB/s]"}},"ac944fecbf31477786aa6af6a29ce637":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3cb4e65b9c12446abe85c6ce4bf33083","placeholder":"​","style":"IPY_MODEL_268443e43dfe4794ba4d6148bee647aa","value":" 215920/215920 [00:07&lt;00:00, 29239.53it/s]"}},"ad22404aae404cec8928ec67b9bfb50f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"adc1dd7637eb4773afe75940948c1f0a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"af3186bef391493aa150e4b2c059c1ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5575e0208d484de2b9f38c346bf06772","IPY_MODEL_9e22cab924824846a9c469ef25a7f42e","IPY_MODEL_787cedc8a9644ca6b27e3b84b3bc611b"],"layout":"IPY_MODEL_5c0d89c0169f467db1848d5bd35df62a"}},"b0c9e412b0804cecb65d79802f145b0c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b29652f3fb774157b9149f2f2b16e682":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b528ebf7c1694f58a969a7bb2e423542":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5fb2ecc894646f182e35d9d2f0cc3fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b7d904dccbc44a3c83fd6a039bb5cde3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b988400c629c410a84b21acc999c2f27":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"baf1587111ac48ba9a4fff7bc5e2ee71":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb1d769dfe194dda826f01f36b10379b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdf2a8713de54e77bddd86dded9e0830":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f18f27f19c644ef5917dfde8f920a8fb","placeholder":"​","style":"IPY_MODEL_10cde17b97054d2dab6608529195f9aa","value":"Downloading: 100%"}},"bfed0914291341549ed16c0f07155bc3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e840565c549434bbc19259d70a9d339","placeholder":"​","style":"IPY_MODEL_747cb88c7edf445fb75a6b683d14e54f","value":" 215920/215920 [00:10&lt;00:00, 26524.34it/s]"}},"c51207431f3a40c3ac396245f2f0aeb6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ca59f9bb14be4261a9ea24007e017224":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cae5dd1101f54a3782f14692f3074f8d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb9ea8a7ba7342bc83fb5d89d46bfdc7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbf77fd80f1e4a479b754f0487565b59":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_02fdd5f686834ac4afb37917167664b8","placeholder":"​","style":"IPY_MODEL_aa3e5e2c3cd04ef88745c1ddb0050f68","value":"100%"}},"cc06fd1ed9254ed19ffa3ee17ee19a3c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cdba4ca5091b49f1a928ffd6cc3c0f11":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cdc670a4c9fa406dafa6f7e473026ea3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d41bdb2269cf496284e0210ce1013eb8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5615f2eb3e74c6aa737ef7222ba6bec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d57ebd7dd85a47a5912e1905ea0e8309":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5ce0af4b1fdd4ab6846ec6a2b056ae77","IPY_MODEL_427cb267433249b5926f61d23ac9fab3","IPY_MODEL_bfed0914291341549ed16c0f07155bc3"],"layout":"IPY_MODEL_b528ebf7c1694f58a969a7bb2e423542"}},"d5ec30e3e4964d2a920b1205bf80a66d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d962b9f2248c4535b9c7c1f23689caae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_323acabc84b544ed9b1b1ba733e56c99","max":30108,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b5fb2ecc894646f182e35d9d2f0cc3fc","value":30108}},"def3aa08969043c9b61f07e2a9e37dfb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_59c1bbe003694ca8b8e83d43ab76412d","max":215920,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1e15472bcd974b7fae7fb8229d0dd6c5","value":215920}},"e2d79d58f252479fa5b94c449b74a60c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6dba378f6514b889e91d27ed8dfe8c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e71fa4c824854898b19a3c865abbcdeb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e79346f1875646cfbdc663ed67a0116c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9684e5747a114f5cbb07c9726e1474b7","IPY_MODEL_1425568c0382468bb61f119bc48fb9df","IPY_MODEL_a7b28df5a69c4e9180407b69ce401670"],"layout":"IPY_MODEL_b0c9e412b0804cecb65d79802f145b0c"}},"e89dd07958a040fda22e259803749d08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8d5efa4ca054d42859ee0133ee30370","max":1112265417,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ca59f9bb14be4261a9ea24007e017224","value":1112265417}},"e8d5efa4ca054d42859ee0133ee30370":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e918f3bed5934e9dbf924606a05431bd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9dde50526ea4ff0bf3a1eabb545a947":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee8f2d29b3af432182abd04e6bb3a680":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"efa535b4c08c45f387fd217a7f6dcce3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f09c65e2d6754bccbdf4f81e7a5c73a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_588739ebee354702b3b9cc29fcc3e9fb","placeholder":"​","style":"IPY_MODEL_6a071947768940028e3a3c2b36cd7510","value":"Downloading: 100%"}},"f0b4f75f96df461cbf26c9a0bda60e35":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f18f27f19c644ef5917dfde8f920a8fb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1f0d5dd0c174f0ba902c4c2ef9c5741":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_531c47b689054cae84a4152fcf5d88ce","IPY_MODEL_761725aa7b6440d38850ad551b57fe04","IPY_MODEL_301140a846154caeadaf91e3999f91ef"],"layout":"IPY_MODEL_4884c8ce4d024d1ea716c6a06c93ab5f"}},"f2bc9c42aea1494da234a15c2acea1f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f58d97547cc1496781406b4e4c489dbd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2fba76e751d54632947059a42f1a9c04","IPY_MODEL_fbad24901c8546be962a0d902059d90b","IPY_MODEL_7c4cf013a912469b979028456747bfec"],"layout":"IPY_MODEL_58d9ca95e2f4423a9f2644750f2a80aa"}},"f5f0d5c367884a4bb8973d51d7efaea7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_19de70fba8a54a6c85b3f80afe98e7a7","IPY_MODEL_7036b45db86546708bddcf6b1b348f1e","IPY_MODEL_4ee2f6c67c534a95a229e9d5113d225e"],"layout":"IPY_MODEL_e71fa4c824854898b19a3c865abbcdeb"}},"f8a800f6fb644c6e88266bfec348369c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9f36f2bbe2f4cd7a9d9b74ce3309678":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d7978edbd0f407299c23c38daf5c66a","placeholder":"​","style":"IPY_MODEL_6465b09b5753494aa6e34585cb991e6e","value":" 211/211 [00:00&lt;00:00, 8.68kB/s]"}},"fbad24901c8546be962a0d902059d90b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_efa535b4c08c45f387fd217a7f6dcce3","max":30108,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7fcacdfa272f4c36b0ee369f6024cc16","value":30108}},"fd1776a2e9cd462d950af6270fd5592a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94ffc84e42e74b81a37e49d8cb77c90d","placeholder":"​","style":"IPY_MODEL_ee8f2d29b3af432182abd04e6bb3a680","value":"100%"}}}}},"nbformat":4,"nbformat_minor":0}
